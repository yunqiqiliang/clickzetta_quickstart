{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sGT7Sjb93Zt6",
   "metadata": {
    "id": "sGT7Sjb93Zt6"
   },
   "source": [
    "# Transforming Unstructured Data from an AWS S3 bucket into RAG-Ready Data in Singdata Lakehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea21043",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abe8f89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ åˆ‡æ¢åˆ°æœ¬åœ°å¼€å‘ç‰ˆæœ¬...\n",
      "âœ… åˆ‡æ¢åˆ°æœ¬åœ°å¼€å‘ç‰ˆæœ¬: /Users/liangmo/Documents/GitHub/unstructured-ingest-clickzetta/unstructured_ingest/__init__.py\n",
      "âœ… DashScope æ”¯æŒå·²æˆåŠŸæ·»åŠ åˆ° EmbedderConfig\n",
      "âœ… DashScope get_embedder æ–¹æ³•æ­£å¸¸å·¥ä½œ\n"
     ]
    }
   ],
   "source": [
    "# æ›¿æ¢ Cell f3af592c - åˆ‡æ¢åˆ°æœ¬åœ°å¼€å‘ç‰ˆæœ¬\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# å¸è½½å·²å®‰è£…çš„ç‰ˆæœ¬å¹¶é‡æ–°å®‰è£…æœ¬åœ°å¼€å‘ç‰ˆæœ¬\n",
    "print(\"ğŸ”„ åˆ‡æ¢åˆ°æœ¬åœ°å¼€å‘ç‰ˆæœ¬...\")\n",
    "!pip uninstall unstructured-ingest -y -q\n",
    "!pip install -e /Users/liangmo/Documents/GitHub/unstructured-ingest-clickzetta/ -q\n",
    "\n",
    "# æ¸…ç†æ¨¡å—ç¼“å­˜ï¼Œå¼ºåˆ¶é‡æ–°å¯¼å…¥\n",
    "modules_to_remove = [module for module in sys.modules.keys() if module.startswith('unstructured_ingest')]\n",
    "for module in modules_to_remove:\n",
    "    if module in sys.modules:\n",
    "        del sys.modules[module]\n",
    "\n",
    "# é‡æ–°å¯¼å…¥\n",
    "import unstructured_ingest\n",
    "print(f\"âœ… åˆ‡æ¢åˆ°æœ¬åœ°å¼€å‘ç‰ˆæœ¬: {unstructured_ingest.__file__}\")\n",
    "\n",
    "# éªŒè¯ DashScope æ”¯æŒ\n",
    "try:\n",
    "    from unstructured_ingest.processes.embedder import EmbedderConfig\n",
    "    # æµ‹è¯•æ˜¯å¦æ”¯æŒ dashscope\n",
    "    test_config = EmbedderConfig(\n",
    "        embedding_provider=\"dashscope\",\n",
    "        embedding_model_name=\"text-embedding-v4\",\n",
    "        embedding_api_key=\"test\"\n",
    "    )\n",
    "    print(\"âœ… DashScope æ”¯æŒå·²æˆåŠŸæ·»åŠ åˆ° EmbedderConfig\")\n",
    "    \n",
    "    # æµ‹è¯• get_embedder æ–¹æ³•\n",
    "    try:\n",
    "        embedder = test_config.get_embedder()\n",
    "        print(\"âœ… DashScope get_embedder æ–¹æ³•æ­£å¸¸å·¥ä½œ\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  get_embedder æ–¹æ³•éœ€è¦ä¿®å¤: {e}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ DashScope æ”¯æŒæ£€æŸ¥å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32e16887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR, force=True)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# if you want to drop the tables before write data, set drop_tables to True\n",
    "drop_tables = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f79dfebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…å¿…éœ€çš„ä¾èµ–\n",
    "# !pip install \"dashscope\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ccc8547c6539d3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:43:55.575099Z",
     "start_time": "2024-07-03T13:43:55.564950Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 378
    },
    "id": "5ccc8547c6539d3b",
    "outputId": "81865be5-be71-4a53-e41f-ac1c75f50f45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/liangmo/yunqidoc/cn_markdown_20250526'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv('.env') # replace with the path to your .env file\n",
    "os.getenv(\"LOCAL_FILE_INPUT_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d199049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… é…ç½®æ›´æ–°:\n",
      "  ä½¿ç”¨ DashScope text-embedding-v4\n",
      "  æ¨¡å‹: text-embedding-v4\n",
      "  ç»´åº¦: 1024\n"
     ]
    }
   ],
   "source": [
    "# ä¿®æ”¹é…ç½®éƒ¨åˆ† - Cell 6501bbf9\n",
    "# Define the table names to use for storing the data in Lakehouse.\n",
    "index_and_table_prefix = \"dashscope_v4_1024_2048_20250611_\"  # æ›´æ–°å‰ç¼€åæ˜ ä½¿ç”¨DashScope v4\n",
    "raw_table_name = f\"{index_and_table_prefix}yunqi_raw_elements\"\n",
    "silver_table_name = f\"{index_and_table_prefix}yunqi_elements\"\n",
    "embeddings_dimensions = 1024  # DashScope text-embedding-v4 çš„ç»´åº¦\n",
    "chunk_max_characters = 2048\n",
    "chunk_overlap = 512\n",
    "embedding_provider = \"dashscope\"  # ä½¿ç”¨ dashscope\n",
    "embedding_model_name = \"text-embedding-v4\"  # ä½¿ç”¨ DashScope v4 æ¨¡å‹\n",
    "api_key = \"sk-7d178531cbd14ce6bba2d16fe3948239\"\n",
    "\n",
    "print(f\"âœ… é…ç½®æ›´æ–°:\")\n",
    "print(f\"  ä½¿ç”¨ DashScope text-embedding-v4\")\n",
    "print(f\"  æ¨¡å‹: {embedding_model_name}\")\n",
    "print(f\"  ç»´åº¦: {embeddings_dimensions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90fcae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the connection parameter to Singdata Lakehouse.\n",
    "_username = os.getenv(\"cz_username\")\n",
    "_password = os.getenv(\"cz_password\")\n",
    "_service = os.getenv(\"cz_service\")\n",
    "_instance = os.getenv(\"cz_instance\")\n",
    "_workspace = os.getenv(\"cz_workspace\")\n",
    "_schema = os.getenv(\"cz_schema\")\n",
    "_vcluster = os.getenv(\"cz_vcluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d1164b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema to use for storing the data in Singdata Lakehouse.\n",
    "raw_table_ddl = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {_schema}.{raw_table_name} (\n",
    "    id STRING, -- Auto-increment sequence\n",
    "    record_locator STRING,\n",
    "    type STRING,\n",
    "    record_id STRING, -- Record identifier from the data source (e.g., record locator in connector metadata)\n",
    "    element_id STRING, -- Unique identifier for the element (SHA-256 or UUID)\n",
    "    filetype STRING, -- File type (e.g., PDF, DOCX, EML, etc.)\n",
    "    file_directory STRING, -- Directory where the file is located\n",
    "    filename STRING, -- File name\n",
    "    last_modified TIMESTAMP, -- Last modified time of the file\n",
    "    languages STRING, -- Document language, supports a list of multiple languages\n",
    "    page_number STRING, -- Page number (applicable for PDF, DOCX, etc.)\n",
    "    text STRING, -- Extracted text content\n",
    "    embeddings VECTOR({embeddings_dimensions}), -- Vector data\n",
    "    parent_id STRING, -- Parent element ID, used to represent element hierarchy\n",
    "    is_continuation BOOLEAN, -- Whether it is a continuation of the previous element (used in chunking)\n",
    "    orig_elements STRING, -- Original element in JSON format (used to store the complete element structure)\n",
    "    element_type STRING, -- Element type (e.g., NarrativeText, Title, Table, etc.)\n",
    "    coordinates STRING, -- Element coordinates (stored in JSONB format)\n",
    "    link_texts STRING, -- Added field: Link text\n",
    "    link_urls STRING, -- Added field: Link URL\n",
    "    email_message_id STRING, -- Added field: Email message ID\n",
    "    sent_from STRING, -- Added field: Sender\n",
    "    sent_to STRING, -- Added field: Recipient\n",
    "    subject STRING, -- Added field: Subject\n",
    "    url STRING, -- Added field: URL\n",
    "    version STRING, -- Added field: Version\n",
    "    date_created TIMESTAMP, -- Added field: Creation date\n",
    "    date_modified TIMESTAMP, -- Added field: Modification date\n",
    "    date_processed TIMESTAMP, -- Added field: Processing date\n",
    "    text_as_html STRING, -- Added field: Text in HTML format\n",
    "    emphasized_text_contents STRING,\n",
    "    emphasized_text_tags STRING,\n",
    "    documents_original_source STRING, -- Added field: Document source\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "silver_table_ddl = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {_schema}.{silver_table_name} (\n",
    "    id STRING, -- Auto-increment sequence\n",
    "    record_locator STRING,\n",
    "    type STRING,\n",
    "    record_id STRING, -- Record identifier from the data source (e.g., record locator in connector metadata)\n",
    "    element_id STRING, -- Unique identifier for the element (SHA-256 or UUID)\n",
    "    filetype STRING, -- File type (e.g., PDF, DOCX, EML, etc.)\n",
    "    file_directory STRING, -- Directory where the file is located\n",
    "    filename STRING, -- File name\n",
    "    last_modified TIMESTAMP, -- Last modified time of the file\n",
    "    languages STRING, -- Document language, supports a list of multiple languages\n",
    "    page_number STRING, -- Page number (applicable for PDF, DOCX, etc.)\n",
    "    text STRING, -- Extracted text content\n",
    "    embeddings vector({embeddings_dimensions}), -- Vector data\n",
    "    parent_id STRING, -- Parent element ID, used to represent element hierarchy\n",
    "    is_continuation BOOLEAN, -- Whether it is a continuation of the previous element (used in chunking)\n",
    "    orig_elements STRING, -- Original element in JSON format (used to store the complete element structure)\n",
    "    element_type STRING, -- Element type (e.g., NarrativeText, Title, Table, etc.)\n",
    "    coordinates STRING, -- Element coordinates (stored in JSONB format)\n",
    "    link_texts STRING, -- Added field: Link text\n",
    "    link_urls STRING, -- Added field: Link URL\n",
    "    email_message_id STRING, -- Added field: Email message ID\n",
    "    sent_from STRING, -- Added field: Sender\n",
    "    sent_to STRING, -- Added field: Recipient\n",
    "    subject STRING, -- Added field: Subject\n",
    "    url STRING, -- Added field: URL\n",
    "    version STRING, -- Added field: Version\n",
    "    date_created TIMESTAMP, -- Added field: Creation date\n",
    "    date_modified TIMESTAMP, -- Added field: Modification date\n",
    "    date_processed TIMESTAMP, -- Added field: Processing date\n",
    "    text_as_html STRING, -- Added field: Text in HTML format\n",
    "    emphasized_text_contents STRING,\n",
    "    emphasized_text_tags STRING,\n",
    "    documents_source STRING, -- Added field: Document source\n",
    "    INDEX {index_and_table_prefix}inverted_text_index_yunqi_cn (text) INVERTED  PROPERTIES('analyzer'='unicode'),\n",
    "    INDEX {index_and_table_prefix}embeddings_vec_index_yunqi_cn(embeddings) USING vector properties (\n",
    "        \"scalar.type\" = \"f32\",\n",
    "        \"distance.function\" = \"cosine_distance\")\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "clean_transformation_data_sql = f\"\"\"\n",
    "INSERT overwrite {_schema}.{silver_table_name}\n",
    "SELECT \n",
    "    id, \n",
    "    record_locator, \n",
    "    type, \n",
    "    record_id, \n",
    "    element_id, \n",
    "    filetype, \n",
    "    file_directory, \n",
    "    filename, \n",
    "    last_modified, \n",
    "    languages, \n",
    "    page_number, \n",
    "    text, \n",
    "    CAST(embeddings AS VECTOR({embeddings_dimensions})) AS embeddings, \n",
    "    parent_id, \n",
    "    is_continuation, \n",
    "    orig_elements, \n",
    "    element_type, \n",
    "    coordinates, \n",
    "    link_texts, \n",
    "    link_urls, \n",
    "    email_message_id, \n",
    "    sent_from, \n",
    "    sent_to, \n",
    "    subject, \n",
    "    url, \n",
    "    version, \n",
    "    date_created, \n",
    "    date_modified, \n",
    "    date_processed, \n",
    "    text_as_html,\n",
    "    emphasized_text_contents, \n",
    "    emphasized_text_tags,\n",
    "    \"https://yunqi.tech/documents\" as documents_source\n",
    "FROM {_schema}.{raw_table_name};\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3a45736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to create the connection to Singdata Lakehouse.\n",
    "from clickzetta.connector import connect\n",
    "import pandas as pd\n",
    "def get_connection(password, username, service, instance, workspace, schema, vcluster):\n",
    "    connection = connect(\n",
    "        password=password,\n",
    "        username=username,\n",
    "        service=service,\n",
    "        instance=instance,\n",
    "        workspace=workspace,\n",
    "        schema=schema,\n",
    "        vcluster=vcluster)\n",
    "    return connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dcd7dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the connection to Singdata Lakehouse.\n",
    "conn = get_connection(password=_password, username=_username, service=_service, instance=_instance, workspace=_workspace, schema=_schema, vcluster=_vcluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b7fcf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to execute SQL statements\n",
    "def excute_sql(conn,sql_statement: str):\n",
    "    with conn.cursor() as cur:\n",
    "\n",
    "        stmt = sql_statement\n",
    "\n",
    "        cur.execute(stmt)\n",
    "\n",
    "        results = cur.fetchall()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f6ad155",
   "metadata": {},
   "outputs": [],
   "source": [
    "if drop_tables:\n",
    "    excute_sql(conn,f\"DROP TABLE IF EXISTS {_schema}.{raw_table_name}\")\n",
    "    excute_sql(conn,f\"DROP TABLE IF EXISTS {_schema}.{silver_table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ba69a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['OPERATION SUCCEED']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Table in  Lakehouse\n",
    "excute_sql(conn, raw_table_ddl)\n",
    "excute_sql(conn, silver_table_ddl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8X_GQ32GQnI",
   "metadata": {
    "id": "a8X_GQ32GQnI"
   },
   "source": [
    "### PDFs/Images/Emails ingestion and preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99881631767c71e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:44:10.587954Z",
     "start_time": "2024-07-03T13:44:04.335563Z"
    },
    "id": "99881631767c71e2"
   },
   "outputs": [],
   "source": [
    "from unstructured_ingest.interfaces import ProcessorConfig\n",
    "from unstructured_ingest.pipeline.pipeline import Pipeline\n",
    "from unstructured_ingest.processes.chunker import ChunkerConfig\n",
    "from unstructured_ingest.processes.connectors.fsspec.s3 import (\n",
    "    S3ConnectionConfig,\n",
    "    S3DownloaderConfig,\n",
    "    S3IndexerConfig,\n",
    "    S3AccessConfig,\n",
    ")\n",
    "from unstructured_ingest.processes.connectors.local import (\n",
    "    LocalIndexerConfig,\n",
    "    LocalDownloaderConfig,\n",
    "    LocalConnectionConfig\n",
    ")\n",
    "from unstructured_ingest.processes.embedder import EmbedderConfig\n",
    "from unstructured_ingest.processes.partitioner import PartitionerConfig\n",
    "from unstructured_ingest.embed.dashscope import DashScopeEmbeddingConfig, DashScopeEmbeddingEncoder\n",
    "\n",
    "\n",
    "from unstructured_ingest.processes.connectors.sql.clickzetta import (\n",
    "    ClickzettaConnectionConfig,\n",
    "    ClickzettaAccessConfig,\n",
    "    ClickzettaUploadStagerConfig,\n",
    "    ClickzettaUploaderConfig\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8397d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf /Users/liangmo/.cache/unstructured/ingest/pipeline/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc718af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿®æ”¹ Pipeline é…ç½® - Cell bac33d0b\n",
    "import os\n",
    "import logging\n",
    "import dashscope\n",
    "\n",
    "# è®¾ç½® DashScope API Key\n",
    "dashscope.api_key = api_key\n",
    "\n",
    "# è®¾ç½®æ›´è¯¦ç»†çš„æ—¥å¿—çº§åˆ«\n",
    "logging.basicConfig(level=logging.DEBUG, force=True)\n",
    "\n",
    "print(f\"ğŸ” é…ç½®æ£€æŸ¥:\")\n",
    "print(f\"  DashScope API Key: {api_key[:10]}...\")\n",
    "print(f\"  Embedding Provider: {embedding_provider}\")\n",
    "print(f\"  Embedding Model: {embedding_model_name}\")\n",
    "print(f\"  Embedding Dimensions: {embeddings_dimensions}\")\n",
    "print(f\"  LOCAL_FILE_INPUT_DIR: {os.getenv('LOCAL_FILE_INPUT_DIR')}\")\n",
    "\n",
    "# æµ‹è¯• DashScope è¿æ¥\n",
    "try:\n",
    "    print(\"\\nğŸ” æµ‹è¯• DashScope è¿æ¥...\")\n",
    "    from dashscope import TextEmbedding\n",
    "    \n",
    "    response = TextEmbedding.call(\n",
    "        model=embedding_model_name,\n",
    "        input=\"æµ‹è¯•è¿æ¥\"\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        embedding = response.output['embeddings'][0]['embedding']\n",
    "        print(f\"âœ… DashScope è¿æ¥æˆåŠŸï¼åµŒå…¥ç»´åº¦: {len(embedding)}\")\n",
    "    else:\n",
    "        print(f\"âŒ DashScope è¿æ¥å¤±è´¥: {response.message}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ DashScope è¿æ¥å¤±è´¥: {e}\")\n",
    "\n",
    "# å…ˆæµ‹è¯•å„ä¸ªç»„ä»¶æ˜¯å¦æ­£å¸¸\n",
    "try:\n",
    "    print(\"\\nğŸ” æµ‹è¯• EmbedderConfig...\")\n",
    "    embedder_config = EmbedderConfig(\n",
    "        embedding_provider=\"dashscope\",\n",
    "        embedding_model_name=embedding_model_name,\n",
    "        embedding_api_key=api_key,\n",
    "    )\n",
    "    print(\"âœ… EmbedderConfig åˆ›å»ºæˆåŠŸ\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ EmbedderConfig åˆ›å»ºå¤±è´¥: {e}\")\n",
    "\n",
    "try:\n",
    "    print(\"\\nğŸ” æµ‹è¯• ClickzettaConnectionConfig...\")\n",
    "    clickzetta_config = ClickzettaConnectionConfig(\n",
    "        access_config=ClickzettaAccessConfig(password=_password),\n",
    "        username=_username,\n",
    "        service=_service,\n",
    "        instance=_instance,\n",
    "        workspace=_workspace,\n",
    "        schema=_schema,\n",
    "        vcluster=_vcluster,\n",
    "    )\n",
    "    print(\"âœ… ClickzettaConnectionConfig åˆ›å»ºæˆåŠŸ\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ClickzettaConnectionConfig åˆ›å»ºå¤±è´¥: {e}\")\n",
    "\n",
    "try:\n",
    "    print(\"\\nğŸ” æµ‹è¯• LocalIndexerConfig...\")\n",
    "    local_config = LocalIndexerConfig(\n",
    "        input_path=os.getenv(\"LOCAL_FILE_INPUT_DIR\"),\n",
    "        file_glob=\"**/*\", \n",
    "        recursive=True\n",
    "    )\n",
    "    print(\"âœ… LocalIndexerConfig åˆ›å»ºæˆåŠŸ\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ LocalIndexerConfig åˆ›å»ºå¤±è´¥: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c6e42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ›¿æ¢ Cell 0f194520 - ä½¿ç”¨å•è¿›ç¨‹è°ƒè¯•æ¨¡å¼\n",
    "try:\n",
    "    print(\"\\nğŸ” åˆ›å»º Pipeline...\")\n",
    "    pipeline = Pipeline.from_configs(\n",
    "        context=ProcessorConfig(\n",
    "            verbose=True,\n",
    "            tqdm=True,\n",
    "            num_processes=1,  # æ”¹ä¸ºå•è¿›ç¨‹è°ƒè¯•\n",
    "        ),\n",
    "\n",
    "        indexer_config=LocalIndexerConfig(\n",
    "            input_path=os.getenv(\"LOCAL_FILE_INPUT_DIR\"),\n",
    "            file_glob=\"**/*\", \n",
    "            recursive=True\n",
    "        ),\n",
    "        downloader_config=LocalDownloaderConfig(),\n",
    "        source_connection_config=LocalConnectionConfig(),\n",
    "\n",
    "        partitioner_config=PartitionerConfig(\n",
    "            partition_by_api=False,\n",
    "            api_key=os.getenv(\"UNSTRUCTURED_API_KEY\"),\n",
    "            partition_endpoint=os.getenv(\"UNSTRUCTURED_URL\"),\n",
    "            strategy=\"hi_res\",\n",
    "            additional_partition_args={\n",
    "                \"split_pdf_page\": True,\n",
    "                \"split_pdf_allow_failed\": True,\n",
    "                \"split_pdf_concurrency_level\": 1  # å‡å°‘å¹¶å‘\n",
    "            }\n",
    "        ),\n",
    "\n",
    "        chunker_config=ChunkerConfig(\n",
    "            chunking_strategy=\"by_title\",\n",
    "            chunk_max_characters=chunk_max_characters,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            chunk_combine_text_under_n_chars=200,\n",
    "        ),\n",
    "\n",
    "        # ä½¿ç”¨ DashScope åµŒå…¥å™¨\n",
    "        embedder_config=EmbedderConfig(\n",
    "            embedding_provider=\"dashscope\",\n",
    "            embedding_model_name=embedding_model_name,\n",
    "            embedding_api_key=api_key,\n",
    "        ),\n",
    "\n",
    "        destination_connection_config=ClickzettaConnectionConfig(\n",
    "            access_config=ClickzettaAccessConfig(password=_password),\n",
    "            username=_username,\n",
    "            service=_service,\n",
    "            instance=_instance,\n",
    "            workspace=_workspace,\n",
    "            schema=_schema,\n",
    "            vcluster=_vcluster,\n",
    "        ),\n",
    "        stager_config=ClickzettaUploadStagerConfig(),\n",
    "        uploader_config=ClickzettaUploaderConfig(\n",
    "            table_name=raw_table_name, \n",
    "            documents_original_source=\"https://yunqi.tech/documents\"\n",
    "        ),\n",
    "    )\n",
    "    print(\"âœ… Pipeline åˆ›å»ºæˆåŠŸ\")\n",
    "    \n",
    "    # è¿è¡Œ pipeline\n",
    "    print(\"\\nğŸš€ è¿è¡Œ Pipeline...\")\n",
    "    pipeline.run()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Pipeline åˆ›å»ºæˆ–è¿è¡Œå¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02177bb7",
   "metadata": {},
   "source": [
    "### Clean/Transformation RAW table and Insert into Silver table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7cc37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You could excute more SQLs to clean and transform data before insert into Silver table.ã€\n",
    "excute_sql(conn, clean_transformation_data_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fb4febe23f1832",
   "metadata": {
    "id": "b3fb4febe23f1832"
   },
   "source": [
    "### Retrieve relevant documents from Singdata Lakehouse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393cb93e9706feba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T18:15:20.149136Z",
     "start_time": "2024-07-08T18:15:20.143790Z"
    },
    "id": "393cb93e9706feba"
   },
   "outputs": [],
   "source": [
    "# ä¿®æ”¹æ£€ç´¢å‡½æ•°ä¸­çš„ç»´åº¦æ£€æŸ¥ - Cell de07d5d7\n",
    "import dashscope\n",
    "from dashscope import TextEmbedding\n",
    "import json\n",
    "\n",
    "# è®¾ç½® DashScope API\n",
    "dashscope.api_key = api_key\n",
    "\n",
    "def get_embedding(query):\n",
    "    \"\"\"ä½¿ç”¨ DashScope è·å–åµŒå…¥\"\"\"\n",
    "    try:\n",
    "        response = TextEmbedding.call(\n",
    "            model=embedding_model_name,  # ç°åœ¨æ˜¯ text-embedding-v4\n",
    "            input=query\n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            embedding = response.output['embeddings'][0]['embedding']\n",
    "            # éªŒè¯ç»´åº¦\n",
    "            if len(embedding) != embeddings_dimensions:\n",
    "                print(f\"âš ï¸  è­¦å‘Š: å®é™…åµŒå…¥ç»´åº¦ {len(embedding)} ä¸é…ç½®ç»´åº¦ {embeddings_dimensions} ä¸åŒ¹é…\")\n",
    "            return embedding\n",
    "        else:\n",
    "            raise Exception(f\"DashScope API error: {response.message}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting embedding: {e}\")\n",
    "        return [0.0] * embeddings_dimensions\n",
    "\n",
    "def retrieve_documents(conn, query: str, num_results: int = 10):\n",
    "    embedding = get_embedding(query)\n",
    "    embedding_list = embedding  # DashScope å·²ç»è¿”å› list æ ¼å¼\n",
    "    \n",
    "    with conn.cursor() as cur:\n",
    "        stmt = f\"\"\"\n",
    "            WITH \n",
    "            vector_embedding_result AS (\n",
    "            SELECT\n",
    "                \"vector_embedding\" as retrieve_method,\n",
    "                record_locator,\n",
    "                type,\n",
    "                filename,\n",
    "                text,\n",
    "                orig_elements,\n",
    "                cosine_distance(embeddings, cast({embedding_list} as vector({embeddings_dimensions}))) AS score\n",
    "            FROM {silver_table_name}\n",
    "            ORDER BY score ASC\n",
    "            LIMIT {num_results} \n",
    "            )\n",
    "            SELECT * FROM vector_embedding_result\n",
    "            ORDER by score ASC;\n",
    "        \"\"\"\n",
    "\n",
    "        cur.execute(stmt)\n",
    "        results = cur.fetchall()\n",
    "        columns = [desc[0] for desc in cur.description]\n",
    "        df = pd.DataFrame(results, columns=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5999c70db27f0a19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T18:15:21.736297Z",
     "start_time": "2024-07-08T18:15:20.686070Z"
    },
    "id": "5999c70db27f0a19",
    "outputId": "9081a8db-d7c9-45b8-e9f4-41c940c254df"
   },
   "outputs": [],
   "source": [
    "query_text = \"åˆ›å»ºç´¢å¼•çš„è¯­æ³•æ˜¯ä»€ä¹ˆï¼Ÿ\"\n",
    "retrieve_documents_df = retrieve_documents(conn, query_text)\n",
    "retrieve_documents_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23a2ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row__text = retrieve_documents_df.iloc[0]['text']\n",
    "print(first_row__text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8d8666",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = retrieve_documents_df.iloc[0]['filename']\n",
    "with conn.cursor() as cur:\n",
    "\n",
    "        stmt = f\"\"\"\n",
    "            WITH \n",
    "            results AS (\n",
    "            SELECT\n",
    "                record_locator,\n",
    "                type,\n",
    "                filename,\n",
    "                text,\n",
    "                orig_elements,\n",
    "            FROM {silver_table_name}\n",
    "            WHERE filename = \"{filename}\"\n",
    "            )\n",
    "            SELECT    *  FROM      results;\n",
    "        \"\"\"\n",
    "\n",
    "        cur.execute(stmt)\n",
    "\n",
    "        results = cur.fetchall()\n",
    "        columns = [desc[0] for desc in cur.description]  # Get column names from cursor description\n",
    "        df = pd.DataFrame(results, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ce8cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = \"\".join(df[\"text\"].astype(str).tolist())\n",
    "print(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553d7a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb = \"ClickZetta\\äº‘å™¨\\Singdataä¹‹é—´çš„å…³ç³»:ClickZettaæ˜¯äº‘å™¨ã€Singdataçš„æŠ€æœ¯å“ç‰Œã€‚äº‘å™¨æ˜¯ClickZettaçš„ä¸­å›½å•†ä¸šå…¬å¸ï¼ŒSingdataæ˜¯ClickZettaçš„æµ·å¤–å•†ä¸šå…¬å¸ã€‚æ‰€ä»¥åœ¨ä¸åŒºåˆ†å•†ä¸šå’ŒæŠ€æœ¯çš„æ—¶å€™ï¼Œä¸‰è€…æ˜¯ç­‰åŒçš„ã€‚å¦å¤–äº‘å™¨ç»å¸¸ä¹Ÿä¼šç”¨åˆ°Yunqiçš„æ±‰è¯­æ‹¼éŸ³åç§°ã€‚\"\n",
    "embedded_kb = get_embedding(kb)\n",
    "embedded_kb = embedded_kb.tolist()\n",
    "add_kb_sql = f\"\"\"\n",
    "INSERT INTO quick_start.clickzetta_doc_kb.{silver_table_name} (\n",
    "  id, type, record_id, element_id, filetype, last_modified, languages, text, embeddings, date_created, date_modified, date_processed\n",
    ") VALUES (\n",
    "  uuid(), 'UserInput', uuid(), uuid(), 'text', CURRENT_TIMESTAMP, '[\"zh-cn\"]',\n",
    "  '{kb}',\n",
    "  CAST('{embedded_kb}' AS vector(float,{embeddings_dimensions})), CURRENT_TIMESTAMP, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28416139",
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as cur:\n",
    "        cur.execute(add_kb_sql)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "unstructured311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
