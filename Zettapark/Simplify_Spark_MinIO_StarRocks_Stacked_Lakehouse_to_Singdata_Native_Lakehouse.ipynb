{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "706c5f5d-c710-4d9b-b7f9-9d045b786612",
   "metadata": {},
   "source": [
    "# Simplify the transition from the Spark_MinIO_StarRocks_Stacked Lakehouse to the Singdata Native Lakehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81df8594-75ca-4ef3-9c62-252f8123edbd",
   "metadata": {},
   "source": [
    "This table summarizes the key differences and similarities between setting up a Stacked Lakehouse using Docker compose and deploying a Native Cloud Lakehouse with a comprehensive cloud data infrastructure.\n",
    "\n",
    "| Stacked Lakehouse | Native Cloud Lakehouse |\n",
    "|-------------------|------------------------|\n",
    "| Deploy Object Storage, Apache Spark, Iceberg catalog, and StarRocks using Docker compose | One-Stop, All in Cloud data infrastructure, includes Object Storage, optimized Iceberg and Singdata Lakehouse for Spark and StarRocks’s workloads |\n",
    "| Load New York City Green Taxi data for the month of May 2023 into the Iceberg data lake | Load New York City Green Taxi data for the month of May 2023 into Singdata Lake volume with RBAC |\n",
    "| Configure StarRocks to access the Iceberg catalog | Singdata Lakehouse access Lake volume directly |\n",
    "| Query the data with StarRocks where the data sits | Query the data with Singdata Lakehouse where the data sits via SQL or Zettapark Python API |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c888fb-e5bd-42c5-b86d-aa1c7272f0e7",
   "metadata": {},
   "source": [
    "## Stacked Lakehouse Overview\n",
    "This stack referenced from the [StarRocks Quick Start: Apache Iceberg Lakehouse](https://docs.starrocks.io/docs/quick_start/iceberg/), comprises of MinIO for object storage, Apache Spark with PySpark for data processing, an Iceberg catalog for metadata management, and StarRocks for real-time analytics, all deployed seamlessly using Docker Compose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3f65d4-e0fc-4da6-9758-04a7d38120e0",
   "metadata": {},
   "source": [
    "## Singdata Lakehouse Overview\n",
    "[Singdata Lakehouse](https://www.singdata.com) provides unified management of data lake files and data warehouse tables through its abstract storage layer (Volume) and Python API. This guide demonstrates how to perform file management operations in the data lake, including uploading (PUT), downloading (GET), and listing (LIST) files.\n",
    "Key Concepts:\n",
    "\n",
    "\n",
    "Volume Storage Abstraction: All data lake storage is mapped to Volume objects.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "External Volume: Managed by customers, supporting integration with cloud storage like AWS S3 and Alibaba Cloud OSS.\n",
    "\n",
    "Internal Volume: Managed by Singdata, divided into USER VOLUME  and TABLE VOLUME.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Python API: Provides a unified interface for seamless integration of files and tables.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e749b79-c770-4f8c-88a0-c3f66ddd7302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install clickzetta_zettapark_python  -U -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ea55951-9c99-4660-a10b-5cefab2fd4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clickzetta.zettapark.session import Session\n",
    "import json,requests\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e9f7e4-69ba-4614-a132-b003daf5867d",
   "metadata": {},
   "source": [
    "## Import Libraries and Create a Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98dd5058-24c9-4777-ae1a-195da8da32c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Lakehouse.....\n",
      "\n",
      "Connected and context as below...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 从配置文件中读取参数\n",
    "with open('config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "print(\"Connecting to Lakehouse.....\\n\")\n",
    "\n",
    "# 创建会话\n",
    "session = Session.builder.configs(config).create()\n",
    "\n",
    "print(\"Connected and context as below...\\n\")\n",
    "\n",
    "# print(session.sql(\"SELECT current_instance_id(), current_workspace(),current_workspace_id(), current_schema(), current_user(),current_user_id(), current_vcluster()\").collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a01e2b6-2463-4822-85bf-b11308e08862",
   "metadata": {},
   "source": [
    "## File Operations\n",
    "\n",
    "Before starting, clean up the USER VOLUME to ensure a clean environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2d7e0c-9e7e-4d5c-8dc4-382bc3826387",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql(\"REMOVE USER VOLUME SUBDIRECTORY '/'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2eb46d-e5de-4b7c-bf7e-4de5b4165b62",
   "metadata": {},
   "source": [
    "### List Files in USER VOLUME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edd6cc0-a157-4ec2-86ed-ddce9ded6ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql(\"LIST USER VOLUME\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036f73a2-5a55-4797-9e04-1305d1887f7b",
   "metadata": {},
   "source": [
    "### Download the dataset with curl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19f8678-dcb0-421b-a93e-303773823bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data/parquet/\n",
    "!curl -o data/parquet/green_tripdata_2023-05.parquet https://raw.githubusercontent.com/StarRocks/demo/master/documentation-samples/iceberg/datasets/green_tripdata_2023-05.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b219af-43ae-43c0-8b19-02aaf2678daa",
   "metadata": {},
   "source": [
    "### Upload Dataset to Singdata Lakehouse USER VOLUME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a69d46-8d22-4e3c-9a82-b9c52c9338ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/parquet/green_tripdata_2023-05.parquet\"\n",
    "session.file.put(file_path,\"volume:user://~/nyc/greentaxis/parquet/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ddeead-6681-45fb-97cd-e60e2f0f17b3",
   "metadata": {},
   "source": [
    "### Verify Upload Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e300ecb-4b74-471f-b74f-f72b78bd5e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|relative_path                                       |url                                                 |size     |last_modified_time         |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|nyc/greentaxis/parquet/green_tripdata_2023-05.p...  |oss://cz-lh-sh-prod/123/workspaces/qiliang_ws_d...  |1673841  |2025-03-10 14:56:29+08:00  |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session.sql(\"LIST USER VOLUME\").show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda564c0-c467-403a-b4c6-68fd4fc9f01b",
   "metadata": {},
   "source": [
    "## Option1: Query file with Singdata Lakehouse SQL Directly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5ca76e-2f2a-45ca-a4ba-8efe3b1eb830",
   "metadata": {},
   "source": [
    "### Verify pickup datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31030367-057f-4a10-904d-3573e4b3537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"nyc/greentaxis/parquet/green_tripdata_2023-05.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16f2f47c-f517-4085-8900-78f5507fe249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "|lpep_pickup_datetime       |\n",
      "-----------------------------\n",
      "|2023-05-01 00:52:10+00:00  |\n",
      "|2023-05-01 00:29:49+00:00  |\n",
      "|2023-05-01 00:25:19+00:00  |\n",
      "|2023-05-01 00:07:06+00:00  |\n",
      "|2023-05-01 00:43:31+00:00  |\n",
      "|2023-05-01 00:51:54+00:00  |\n",
      "|2023-05-01 00:27:46+00:00  |\n",
      "|2023-05-01 00:27:14+00:00  |\n",
      "|2023-05-01 00:24:14+00:00  |\n",
      "|2023-05-01 00:46:55+00:00  |\n",
      "-----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session.sql(f\"SELECT lpep_pickup_datetime FROM user volume  using parquet files('{file_path}')\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416b859f-0020-4f6a-9eaf-b56d84a36486",
   "metadata": {},
   "source": [
    "### Find the busy hours\n",
    "This query aggregates the trips on the hour of the day and shows that the busiest hour of the day is 18:00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea86fac5-ff2b-44b0-909b-3e5f5335a36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "|trips  |hour_of_day  |\n",
      "-----------------------\n",
      "|5381   |18           |\n",
      "|5253   |17           |\n",
      "|5091   |16           |\n",
      "|4736   |15           |\n",
      "|4393   |14           |\n",
      "|4275   |19           |\n",
      "|3893   |12           |\n",
      "|3816   |11           |\n",
      "|3685   |13           |\n",
      "|3616   |9            |\n",
      "|3530   |10           |\n",
      "|3361   |20           |\n",
      "|3315   |8            |\n",
      "|2917   |21           |\n",
      "|2680   |7            |\n",
      "|2322   |22           |\n",
      "|1735   |23           |\n",
      "|1202   |6            |\n",
      "|1189   |0            |\n",
      "|806    |1            |\n",
      "|606    |2            |\n",
      "|513    |3            |\n",
      "|451    |5            |\n",
      "|408    |4            |\n",
      "-----------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session.sql(f\"SELECT COUNT(*) AS trips, hour(lpep_pickup_datetime) AS hour_of_day FROM user volume  using parquet files('{file_path}') GROUP BY hour_of_day ORDER BY trips DESC\").show(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a61ac01-16a7-4695-84f1-d9fb07c22cd6",
   "metadata": {},
   "source": [
    "## Option2: Query File with Singdata Lakehouse Zettapark Python API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd93d0a4-b3c2-43d1-afba-f55c15c6d9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clickzetta.zettapark.functions import hour, count, col, from_utc_timestamp\n",
    "from clickzetta.zettapark.types import StructType, StructField, LongType, StringType, TimestampType, DoubleType\n",
    "schema = StructType([StructField(\"lpep_pickup_datetime\", TimestampType()), StructField(\"total_amount\", DoubleType())])\n",
    "path = \"volume:user://~/nyc/greentaxis/parquet/green_tripdata_2023-05.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a03f30-c4c6-4f86-bdbc-23ccf040760a",
   "metadata": {},
   "source": [
    "### Verify pickup datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49e12cae-9e08-4fd5-ab49-86f9369935b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "|lpep_pickup_datetime       |total_amount  |lpep_pickup_utc            |\n",
      "------------------------------------------------------------------------\n",
      "|2023-05-01 08:52:10+08:00  |31.4          |2023-05-01 00:52:10+08:00  |\n",
      "|2023-05-01 08:29:49+08:00  |40.55         |2023-05-01 00:29:49+08:00  |\n",
      "|2023-05-01 08:25:19+08:00  |14.16         |2023-05-01 00:25:19+08:00  |\n",
      "|2023-05-01 08:07:06+08:00  |32.57         |2023-05-01 00:07:06+08:00  |\n",
      "|2023-05-01 08:43:31+08:00  |9.0           |2023-05-01 00:43:31+08:00  |\n",
      "|2023-05-01 08:51:54+08:00  |12.5          |2023-05-01 00:51:54+08:00  |\n",
      "|2023-05-01 08:27:46+08:00  |51.25         |2023-05-01 00:27:46+08:00  |\n",
      "|2023-05-01 08:27:14+08:00  |20.4          |2023-05-01 00:27:14+08:00  |\n",
      "|2023-05-01 08:24:14+08:00  |20.88         |2023-05-01 00:24:14+08:00  |\n",
      "|2023-05-01 08:46:55+08:00  |21.72         |2023-05-01 00:46:55+08:00  |\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parquet_loaded = session.read.option(\"FORMAT_NAME\", \"parquet\").schema(schema).parquet(path)\n",
    "\n",
    "parquet_converted = parquet_loaded.withColumn(\n",
    "    \"lpep_pickup_utc\", \n",
    "    from_utc_timestamp(col(\"lpep_pickup_datetime\"), \"Pacific/Pitcairn\")  \n",
    ")\n",
    "\n",
    "parquet_converted.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ffce60-9959-4a3d-b137-7f5913aa09f9",
   "metadata": {},
   "source": [
    "### Find the busy hours\n",
    "This query aggregates the trips on the hour of the day and shows that the busiest hour of the day is 18:00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfde41bc-6e8f-4643-ab63-9db3a4d7f966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "|trips  |hour_of_day  |\n",
      "-----------------------\n",
      "|5381   |18           |\n",
      "|5253   |17           |\n",
      "|5091   |16           |\n",
      "|4736   |15           |\n",
      "|4393   |14           |\n",
      "|4275   |19           |\n",
      "|3893   |12           |\n",
      "|3816   |11           |\n",
      "|3685   |13           |\n",
      "|3616   |9            |\n",
      "|3530   |10           |\n",
      "|3361   |20           |\n",
      "|3315   |8            |\n",
      "|2917   |21           |\n",
      "|2680   |7            |\n",
      "|2322   |22           |\n",
      "|1735   |23           |\n",
      "|1202   |6            |\n",
      "|1189   |0            |\n",
      "|806    |1            |\n",
      "|606    |2            |\n",
      "|513    |3            |\n",
      "|451    |5            |\n",
      "|408    |4            |\n",
      "-----------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data and process timezone\n",
    "greentaxis_df = session.read.option(\"FORMAT_NAME\", \"parquet\").schema(schema).parquet(path)\n",
    "result_df = (greentaxis_df\n",
    "    # Convert local time (e.g., New York) to UTC time‌‌:ml-citation{ref=\"3,4\" data=\"citationList\"}\n",
    "    .withColumn(\"ltz_time\", from_utc_timestamp(col(\"lpep_pickup_datetime\"), \"Pacific/Pitcairn\"))\n",
    "    # Extract hour from UTC time (adjust timezone inversely if needed)\n",
    "    .withColumn(\"hour_of_day\", hour(\"ltz_time\"))  \n",
    "    .groupBy(\"hour_of_day\")\n",
    "    .agg(count(\"*\").alias(\"trips\"))\n",
    "    .orderBy(\"trips\", ascending=False)\n",
    ")\n",
    "\n",
    "# Adjust column order (optional)\n",
    "result_df = result_df.select(\"trips\", \"hour_of_day\")\n",
    "result_df.show(24)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e358203c-38f8-4360-aaa4-c706b6b4cf38",
   "metadata": {},
   "source": [
    "## Close the Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c49080e1-5138-4dd5-a545-144fe24a5903",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848270a8-9ffd-45dd-9e8f-9eab757c1e05",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Through this guide, you have learned the advantages of Native Cloud Lakehouse:\n",
    "\n",
    "-‌  **Integrated Cloud Infrastructure**‌\n",
    "Provides a fully managed, all-in-one cloud platform with pre-optimized components (Object Storage, Iceberg, Singdata Lakehouse), eliminating complex multi-tool orchestration and ensuring seamless compatibility for Spark and StarRocks workloads‌.\n",
    "\n",
    "‌-‌  **Enhanced Data Governance**‌\n",
    "Supports Role-Based Access Control (RBAC) for secure data management within Singdata Lake Volume, enabling granular permissions and compliance with enterprise security policies‌.\n",
    "\n",
    "-‌  **Direct Data Query**\n",
    "Allows Singdata Lakehouse to query data directly from the Lake Volume without intermediate layers, reducing latency and simplifying architecture‌.\n",
    "\n",
    "‌-‌  **Flexible Query Capabilities**‌\n",
    "Enables unified data access via SQL or Zettapark Python API, catering to diverse analytical workflows while maintaining data locality for efficient computation‌.\n",
    "\n",
    "‌-‌  **Optimized Storage and Scalability**‌\n",
    "Leverages Singdata optimizations for Iceberg and scalable object storage, ensuring cost-efficiency and adaptability to large datasets‌.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c35396d-7659-4c31-8bf2-85176cfe661c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
