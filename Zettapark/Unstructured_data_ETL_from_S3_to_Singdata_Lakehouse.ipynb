{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sGT7Sjb93Zt6",
   "metadata": {
    "id": "sGT7Sjb93Zt6"
   },
   "source": [
    "# Transforming Unstructured Data from an AWS S3 bucket into RAG-Ready Data in Singdata Lakehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea21043",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aab86273",
   "metadata": {},
   "source": [
    "### Unified Processing of Unstructured and Structured Data in a Lakehouse for RAG Applications\n",
    "\n",
    "Developing Retrieval-Augmented Generation (RAG) applications within a Lakehouse architecture presents specific challenges. Integrating diverse data types like text, images, videos, and structured tables requires a robust and flexible architecture. Ensuring data quality and consistency across different formats and sources necessitates comprehensive validation and transformation processes. Managing and storing large volumes of unstructured and structured data efficiently while maintaining scalability and performance is a significant challenge. The processing and analysis of these data types together demand advanced algorithms and substantial computing power. Additionally, robust data governance, security, and compliance across various data types and sources add to the complexity.\n",
    "\n",
    "Despite these challenges, the unified processing of unstructured and structured data is essential for RAG application development. This approach enables the integration of diverse data types, providing a holistic view and uncovering deeper insights that might not be apparent when analyzing data separately. A unified approach streamlines operations, reducing the need for multiple systems, thus simplifying maintenance and lowering operational costs. It ensures data consistency and accuracy, improving the reliability of data-driven decisions. Unified processing allows for advanced analytics, combining insights from different data types for comprehensive and actionable insights. This approach optimizes resource utilization, enhances scalability and flexibility, simplifies architecture, and improves data consistency by reducing data duplication and movement. Furthermore, a simplified architecture with unified processing reduces operational overhead, improves development efficiency, and enhances data consistency, making it crucial for effective and streamlined RAG applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cb6079",
   "metadata": {},
   "source": [
    "\n",
    "### Unified Data Pipeline Solution Overview\n",
    "\n",
    "**Data Source:**\n",
    "- Unstructured files on AWS S3 (PDF, Email, JPG, etc.)\n",
    "\n",
    "**AI Data Transformation:**\n",
    "- Transform unstructured data into JSON format, including embeddings, text summaries, and image summaries.\n",
    "\n",
    "**Data Load into Singdata Lakehouse:**\n",
    "- Load raw data into the `raw_table`, storing various metadata and content related to files and elements.\n",
    "\n",
    "**Data Clean and Transform (Singdata Lakehouse Vector/Inverted INDEX):**\n",
    "- Clean and transform raw data into the `silver_table` with vector index and inverted index.\n",
    "\n",
    "**Data Retrieval (Singdata Lakehouse SQL):**\n",
    "- Perform vector and text searches using Singdata Lakehouse SQL to retrieve and analyze data.\n",
    "\n",
    "\n",
    "![Image Alt Text](./image/UnstructuredDataPipelineSingdata.png)\n",
    "\n",
    "### Key Components:\n",
    "\n",
    "**AWS S3:** Store unstructured data\n",
    "\n",
    "**Unstructured:** Ingesting Unstructured Data from S3, Transform unstructured data into JSON format\n",
    "\n",
    "**Unstructured Singdata Lakehouse Connector:** Load data into Singdata Lakehouse\n",
    "\n",
    "**Singdata Lakehouse:** Store and manage transformed data for RAG Application with Vector Index and Inverted Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138e15d87f040227",
   "metadata": {
    "id": "138e15d87f040227"
   },
   "source": [
    "\n",
    "In this quick tutorial we'll ingest PDFs/Emails/Images from an S3 bucket in same directory, transform them into a normalized JSON with Unstructured, which we will then chunk, embed and load into Singdata Lakehouse table.\n",
    "\n",
    "Then RAG application could retrieve the data in Singdata Lakehouse and get the embeddings and the text/graph content in a format that is ready to be used in a RAG application.\n",
    "\n",
    "### Prerequisites:\n",
    "\n",
    "A. Get your [Unstructured Serverless API key](https://www.google.com/url?q=https%3A%2F%2Funstructured.io%2Fapi-key-hosted). It comes with a 14-day trial, and a cap of 1000 pages/day.\n",
    "\n",
    "B. Get your [Singdata Lakehouse Account](https://singdata.com/). It comes with 1 month trial and ï¿¥200 coupons.\n",
    "\n",
    "C. Create an AWS S3 bucket, and populate it with PDFs of choice. Make sure to note down your credentials.\n",
    "\n",
    "D. Install the necessary libraries:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:42:15.075048Z",
     "start_time": "2024-07-03T13:41:09.778849Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "initial_id",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "8fcc1c00-faaa-4f35-a8e0-8f4eb50194b2"
   },
   "source": [
    "1, Open a terminal and create new Python3.9.21 environment:unstructured\n",
    "\n",
    "conda create -n unstructured python=3.9\n",
    "\n",
    "conda activate unstructured\n",
    "\n",
    "Then select unstructured as current environment\n",
    "\n",
    "2, You could contact with qiliang@clickzetta.com to get unstructured_ingest-0.5.5-py3-none-any.whl.\n",
    "\n",
    "!pip install -U dist/unstructured_ingest-0.5.5-py3-none-any.whl --force-reinstall\n",
    "\n",
    "!pip install -U \"unstructured-ingest[s3, pdf, clickzetta, embed-huggingface]\"\n",
    "\n",
    "!pip install --force-reinstall \"unstructured-ingest[clickzetta]\"\n",
    "\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e16887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# if you want to drop the tables, set drop_tables to True\n",
    "drop_tables = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uNB1tW_F4WYk",
   "metadata": {
    "id": "uNB1tW_F4WYk"
   },
   "source": [
    "### Load env variables\n",
    "\n",
    "In this example we're loading the environment variables with all the secrets from a file in Localfile. The .evn file includes the following variables:\n",
    "\n",
    "cz_username: Username for connecting to the service or system\n",
    "\n",
    "cz_password: Password for connecting to the service or system\n",
    "\n",
    "cz_service: Name of the service or system to connect to\n",
    "\n",
    "cz_instance: Instance name of the service or system to connect to\n",
    "\n",
    "cz_workspace: Workspace name of the service or system to connect to\n",
    "\n",
    "cz_schema: Schema name of the service or system to connect to\n",
    "\n",
    "cz_vcluster: Virtual cluster name of the service or system to connect to\n",
    "\n",
    "AWS_KEY: Key for connecting to AWS services\n",
    "\n",
    "AWS_SECRET: Secret key for connecting to AWS services\n",
    "\n",
    "AWS_S3_NAME: Bucket name for connecting to AWS S3 service\n",
    "\n",
    "UNSTRUCTURED_API_KEY: API key for connecting to the UNSTRUCTURED API\n",
    "\n",
    "UNSTRUCTURED_URL: URL for connecting to the UNSTRUCTURED API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccc8547c6539d3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:43:55.575099Z",
     "start_time": "2024-07-03T13:43:55.564950Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 378
    },
    "id": "5ccc8547c6539d3b",
    "outputId": "81865be5-be71-4a53-e41f-ac1c75f50f45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv('./.env') # replace with the path to your .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be5cefe",
   "metadata": {},
   "source": [
    "### Put Unstructure Data in AWS S3\n",
    "\n",
    "![Image Alt Text](./image/files_in_s3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-80mXole4qAe",
   "metadata": {
    "id": "-80mXole4qAe"
   },
   "source": [
    "### Create index in Singdata Lakehouse\n",
    "\n",
    "Before we build the unstructured data preprocessing pipeline, let's create a Singdata Lakehouse schema and a table in it to store the processed data.\n",
    "\n",
    "For an example of a schema, please refer to [Unstructured documentation](https://docs.unstructured.io/api-reference/ingest/destination-connector/singlestore#singlestore-table-schema). If you'll be using the schema from the documentation, make sure that the `dims` value for the embeddings matches the number of dimensions of the embeddings model you choose to use. In this example it's set to 768, but your embedding model may produce vectors of a different dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d199049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the table names to use for storing the data in Lakehouse.\n",
    "raw_table_name = \"raw_elements\"\n",
    "silver_table_name = \"elements\"\n",
    "embeddings_dimensions = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fcae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the connection parameter to Singdata Lakehouse.\n",
    "_username = os.getenv(\"cz_username\")\n",
    "_password = os.getenv(\"cz_password\")\n",
    "_service = os.getenv(\"cz_service\")\n",
    "_instance = os.getenv(\"cz_instance\")\n",
    "_workspace = os.getenv(\"cz_workspace\")\n",
    "_schema = os.getenv(\"cz_schema\")\n",
    "_vcluster = os.getenv(\"cz_vcluster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191ee142",
   "metadata": {},
   "source": [
    "This silver layer table is designed to store various metadata and content related to files and elements. The two indexes optimize the performance of specific queries:\n",
    "\n",
    "The inverted text index enhances full-text search capabilities, making it easier to find records based on text content.\n",
    "\n",
    "The embeddings vector index optimizes similarity searches on vector data, which is useful for tasks that involve comparing and finding similar elements based on their embeddings.\n",
    "\n",
    "Benefits for RAG (Retrieval-Augmented Generation) Application Development:\n",
    "\n",
    "Enhanced Search Efficiency: By supporting both inverted and vector searches, this table allows RAG applications to efficiently retrieve relevant information based on both text content and semantic similarity. This enhances the model's ability to find and generate contextually relevant responses.\n",
    "\n",
    "Improved Accuracy: The combination of full-text and similarity searches ensures that RAG applications can access a broader range of relevant data, improving the accuracy and relevance of generated content.\n",
    "\n",
    "Scalability: With optimized indexes, the table can handle large volumes of data and perform searches quickly, supporting the scalability needs of RAG applications.\n",
    "\n",
    "Simplified Architecture: Combining inverted text and vector search capabilities in a single table eliminates the need for separate text and vector search databases. This simplifies maintenance, reduces operational overhead, and improves development efficiency.\n",
    "\n",
    "Data Consistency: Reducing the number of data replicas from three to one enhances data consistency, minimizes data duplication, and reduces the need for data synchronization and movement.\n",
    "\n",
    "Overall, these indexes ensure that searches and retrievals on the text and embeddings fields are performed efficiently, supporting quick and accurate query results, which are crucial for the development of effective and streamlined RAG applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1164b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema to use for storing the data in Singdata Lakehouse.\n",
    "raw_table_ddl = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {_schema}.{raw_table_name} (\n",
    "    id STRING, -- Auto-increment sequence\n",
    "    record_locator STRING,\n",
    "    type STRING,\n",
    "    record_id STRING, -- Record identifier from the data source (e.g., record locator in connector metadata)\n",
    "    element_id STRING, -- Unique identifier for the element (SHA-256 or UUID)\n",
    "    filetype STRING, -- File type (e.g., PDF, DOCX, EML, etc.)\n",
    "    file_directory STRING, -- Directory where the file is located\n",
    "    filename STRING, -- File name\n",
    "    last_modified TIMESTAMP, -- Last modified time of the file\n",
    "    languages STRING, -- Document language, supports a list of multiple languages\n",
    "    page_number STRING, -- Page number (applicable for PDF, DOCX, etc.)\n",
    "    text STRING, -- Extracted text content\n",
    "    embeddings STRING, -- Vector data\n",
    "    parent_id STRING, -- Parent element ID, used to represent element hierarchy\n",
    "    is_continuation BOOLEAN, -- Whether it is a continuation of the previous element (used in chunking)\n",
    "    orig_elements STRING, -- Original element in JSON format (used to store the complete element structure)\n",
    "    element_type STRING, -- Element type (e.g., NarrativeText, Title, Table, etc.)\n",
    "    coordinates STRING, -- Element coordinates (stored in JSONB format)\n",
    "    link_texts STRING, -- Added field: Link text\n",
    "    link_urls STRING, -- Added field: Link URL\n",
    "    email_message_id STRING, -- Added field: Email message ID\n",
    "    sent_from STRING, -- Added field: Sender\n",
    "    sent_to STRING, -- Added field: Recipient\n",
    "    subject STRING, -- Added field: Subject\n",
    "    url STRING, -- Added field: URL\n",
    "    version STRING, -- Added field: Version\n",
    "    date_created TIMESTAMP, -- Added field: Creation date\n",
    "    date_modified TIMESTAMP, -- Added field: Modification date\n",
    "    date_processed TIMESTAMP, -- Added field: Processing date\n",
    "    text_as_html STRING, -- Added field: Text in HTML format\n",
    "    emphasized_text_contents STRING,\n",
    "    emphasized_text_tags STRING\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "silver_table_ddl = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {_schema}.{silver_table_name} (\n",
    "    id STRING, -- Auto-increment sequence\n",
    "    record_locator STRING,\n",
    "    type STRING,\n",
    "    record_id STRING, -- Record identifier from the data source (e.g., record locator in connector metadata)\n",
    "    element_id STRING, -- Unique identifier for the element (SHA-256 or UUID)\n",
    "    filetype STRING, -- File type (e.g., PDF, DOCX, EML, etc.)\n",
    "    file_directory STRING, -- Directory where the file is located\n",
    "    filename STRING, -- File name\n",
    "    last_modified TIMESTAMP, -- Last modified time of the file\n",
    "    languages STRING, -- Document language, supports a list of multiple languages\n",
    "    page_number STRING, -- Page number (applicable for PDF, DOCX, etc.)\n",
    "    text STRING, -- Extracted text content\n",
    "    embeddings vector({embeddings_dimensions}), -- Vector data\n",
    "    parent_id STRING, -- Parent element ID, used to represent element hierarchy\n",
    "    is_continuation BOOLEAN, -- Whether it is a continuation of the previous element (used in chunking)\n",
    "    orig_elements STRING, -- Original element in JSON format (used to store the complete element structure)\n",
    "    element_type STRING, -- Element type (e.g., NarrativeText, Title, Table, etc.)\n",
    "    coordinates STRING, -- Element coordinates (stored in JSONB format)\n",
    "    link_texts STRING, -- Added field: Link text\n",
    "    link_urls STRING, -- Added field: Link URL\n",
    "    email_message_id STRING, -- Added field: Email message ID\n",
    "    sent_from STRING, -- Added field: Sender\n",
    "    sent_to STRING, -- Added field: Recipient\n",
    "    subject STRING, -- Added field: Subject\n",
    "    url STRING, -- Added field: URL\n",
    "    version STRING, -- Added field: Version\n",
    "    date_created TIMESTAMP, -- Added field: Creation date\n",
    "    date_modified TIMESTAMP, -- Added field: Modification date\n",
    "    date_processed TIMESTAMP, -- Added field: Processing date\n",
    "    text_as_html STRING, -- Added field: Text in HTML format\n",
    "    emphasized_text_contents STRING,\n",
    "    emphasized_text_tags STRING,\n",
    "    INDEX inverted_text_index (text) INVERTED  PROPERTIES('analyzer'='unicode'),\n",
    "    INDEX embeddings_vec_idx(embeddings) USING vector properties (\n",
    "        \"scalar.type\" = \"f32\",\n",
    "        \"distance.function\" = \"l2_distance\")\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "clean_transformation_data_sql = f\"\"\"\n",
    "INSERT INTO {_schema}.{silver_table_name}\n",
    "SELECT \n",
    "    id, \n",
    "    record_locator, \n",
    "    type, \n",
    "    record_id, \n",
    "    element_id, \n",
    "    filetype, \n",
    "    file_directory, \n",
    "    filename, \n",
    "    last_modified, \n",
    "    languages, \n",
    "    page_number, \n",
    "    text, \n",
    "    CAST(embeddings AS VECTOR({embeddings_dimensions})) AS embeddings, \n",
    "    parent_id, \n",
    "    is_continuation, \n",
    "    orig_elements, \n",
    "    element_type, \n",
    "    coordinates, \n",
    "    link_texts, \n",
    "    link_urls, \n",
    "    email_message_id, \n",
    "    sent_from, \n",
    "    sent_to, \n",
    "    subject, \n",
    "    url, \n",
    "    version, \n",
    "    date_created, \n",
    "    date_modified, \n",
    "    date_processed, \n",
    "    text_as_html,\n",
    "    emphasized_text_contents, \n",
    "    emphasized_text_tags \n",
    "FROM {_schema}.{raw_table_name};\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a45736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to create the connection to Singdata Lakehouse.\n",
    "from clickzetta.connector import connect\n",
    "import pandas as pd\n",
    "def get_connection(password, username, service, instance, workspace, schema, vcluster):\n",
    "    connection = connect(\n",
    "        password=password,\n",
    "        username=username,\n",
    "        service=service,\n",
    "        instance=instance,\n",
    "        workspace=workspace,\n",
    "        schema=schema,\n",
    "        vcluster=vcluster)\n",
    "    return connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcd7dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the connection to Singdata Lakehouse.\n",
    "conn = get_connection(password=_password, username=_username, service=_service, instance=_instance, workspace=_workspace, schema=_schema, vcluster=_vcluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7fcf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to execute SQL statements\n",
    "def excute_sql(conn,sql_statement: str):\n",
    "    with conn.cursor() as cur:\n",
    "\n",
    "        stmt = sql_statement\n",
    "\n",
    "        cur.execute(stmt)\n",
    "\n",
    "        results = cur.fetchall()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6ad155",
   "metadata": {},
   "outputs": [],
   "source": [
    "if drop_tables:\n",
    "    excute_sql(conn,f\"DROP TABLE IF EXISTS {_schema}.{raw_table_name}\")\n",
    "    excute_sql(conn,f\"DROP TABLE IF EXISTS {_schema}.{silver_table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba69a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['OPERATION SUCCEED']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Table in Singdata Lakehouse\n",
    "excute_sql(conn, raw_table_ddl)\n",
    "excute_sql(conn, silver_table_ddl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sxDcltMB5i17",
   "metadata": {
    "id": "sxDcltMB5i17"
   },
   "source": [
    "Creating a database may take a few seconds. Let's check the status. We want to make sure that it says `healthy` before we begin writing into it.\n",
    "\n",
    "![Image Alt Text](./image/unstructured_tables.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8X_GQ32GQnI",
   "metadata": {
    "id": "a8X_GQ32GQnI"
   },
   "source": [
    "### PDFs/Images/Emails ingestion and preprocessing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EQ0GXjYMGUqO",
   "metadata": {
    "id": "EQ0GXjYMGUqO"
   },
   "source": [
    "Unstructured ingestion and transformation pipeline is compiled from a number of necessary configs. These don't have to be in the exact same order.\n",
    "\n",
    "* `ProcessorConfig`: defines general processing behavior\n",
    "\n",
    "* `S3IndexerConfig`, `S3DownloaderConfig`, `S3ConnectionConfig`: control data ingestion from S3, including source location, and authentication options.\n",
    "\n",
    "* `PartitionerConfig`: describes partitioning behavior. Here we only set up authentication for the Unstructured API, but you can also control [partitioning parameters](https://docs.unstructured.io/api-reference/ingest/ingest-configuration/partition-configuration) such as partitioning strategy through this config. We're going with the defaults.  \n",
    "\n",
    "* `ChunkerConfig`: defines the chunking strategy, and chunk sizes.\n",
    "\n",
    "* `EmbedderConfig`: sets up connection to an embedding model provider to generate embeddings for data chunks.\n",
    "\n",
    "* `ClickzettaConnectionConfig`, `ClickzettaUploadStagerConfig`, `ClickzettaUploaderConfig`: control the final step of the pipeline - data loading into Singdata Lakehouse RAW table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99881631767c71e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:44:10.587954Z",
     "start_time": "2024-07-03T13:44:04.335563Z"
    },
    "id": "99881631767c71e2"
   },
   "outputs": [],
   "source": [
    "from unstructured_ingest.v2.interfaces import ProcessorConfig\n",
    "from unstructured_ingest.v2.pipeline.pipeline import Pipeline\n",
    "from unstructured_ingest.v2.processes.chunker import ChunkerConfig\n",
    "from unstructured_ingest.v2.processes.connectors.fsspec.s3 import (\n",
    "    S3ConnectionConfig,\n",
    "    S3DownloaderConfig,\n",
    "    S3IndexerConfig,\n",
    "    S3AccessConfig,\n",
    ")\n",
    "from unstructured_ingest.v2.processes.embedder import EmbedderConfig\n",
    "from unstructured_ingest.v2.processes.partitioner import PartitionerConfig\n",
    "\n",
    "from unstructured_ingest.v2.processes.connectors.sql.clickzetta import (\n",
    "    ClickzettaConnectionConfig,\n",
    "    ClickzettaAccessConfig,\n",
    "    ClickzettaUploadStagerConfig,\n",
    "    ClickzettaUploaderConfig\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4972ded3e9fd8ca2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:43:35.287223Z",
     "start_time": "2024-07-03T14:43:27.689950Z"
    },
    "id": "4972ded3e9fd8ca2",
    "outputId": "ddc64a27-5d80-4d3c-e6dc-a9ec216bd407"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline.from_configs(\n",
    "\n",
    "    context=ProcessorConfig(\n",
    "        verbose=True,\n",
    "        tqdm=True,\n",
    "        num_processes=20,\n",
    "    ),\n",
    "\n",
    "    indexer_config=S3IndexerConfig(remote_url=os.getenv(\"AWS_S3_NAME\")),\n",
    "    downloader_config=S3DownloaderConfig(),\n",
    "    source_connection_config=S3ConnectionConfig(\n",
    "        access_config=S3AccessConfig(\n",
    "            key=os.getenv(\"AWS_KEY\"),\n",
    "            secret=os.getenv(\"AWS_SECRET\"))\n",
    "    ),\n",
    "\n",
    "    partitioner_config=PartitionerConfig(\n",
    "        partition_by_api=True,\n",
    "        api_key=os.getenv(\"UNSTRUCTURED_API_KEY\"),\n",
    "        partition_endpoint=os.getenv(\"UNSTRUCTURED_URL\"),\n",
    "    ),\n",
    "\n",
    "    chunker_config=ChunkerConfig(\n",
    "        chunking_strategy=\"by_title\",\n",
    "        chunk_max_characters=512,\n",
    "        chunk_combine_text_under_n_chars=200,\n",
    "    ),\n",
    "\n",
    "    embedder_config=EmbedderConfig(\n",
    "        embedding_provider=\"huggingface\", # \"langchain-huggingface\" for ingest v<0.23\n",
    "        embedding_model_name=\"BAAI/bge-base-en-v1.5\",\n",
    "    ),\n",
    "\n",
    "    destination_connection_config=ClickzettaConnectionConfig(\n",
    "        access_config=ClickzettaAccessConfig(password=_password),\n",
    "        username=_username,\n",
    "        service=_service,\n",
    "        instance=_instance,\n",
    "        workspace=_workspace,\n",
    "        schema=_schema,\n",
    "        vcluster=_vcluster,\n",
    "    ),\n",
    "    stager_config=ClickzettaUploadStagerConfig(),\n",
    "    uploader_config=ClickzettaUploaderConfig(table_name=raw_table_name),\n",
    ")\n",
    "\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02177bb7",
   "metadata": {},
   "source": [
    "### Clean/Transformation RAW table and Insert into Silver table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7cc37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['OPERATION SUCCEED']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You could excute more SQLs to clean and transform data before insert into Silver table.ã\n",
    "excute_sql(conn, clean_transformation_data_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mSCldyUAGmbF",
   "metadata": {
    "id": "mSCldyUAGmbF"
   },
   "source": [
    "### Check the RAG data Ready outputs\n",
    "\n",
    "Let's connect to the Singdata Lakehouse. In the logs to the previous cell, you can see how many elements have been uploaded during the Upload Step for each document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16060c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_rag_ready_data(conn,  num_results: int = 5):\n",
    "    with conn.cursor() as cur:\n",
    "\n",
    "        stmt = f\"\"\"\n",
    "            SELECT\n",
    "                *\n",
    "            FROM {silver_table_name}\n",
    "            LIMIT {num_results}\n",
    "        \"\"\"\n",
    "\n",
    "        cur.execute(stmt)\n",
    "\n",
    "        results = cur.fetchall()\n",
    "        columns = [desc[0] for desc in cur.description]  # Get column names from cursor description\n",
    "        rag_ready_data_df = pd.DataFrame(results, columns=columns)\n",
    "    return rag_ready_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577b201f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>record_locator</th>\n",
       "      <th>type</th>\n",
       "      <th>record_id</th>\n",
       "      <th>element_id</th>\n",
       "      <th>filetype</th>\n",
       "      <th>file_directory</th>\n",
       "      <th>filename</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>languages</th>\n",
       "      <th>...</th>\n",
       "      <th>sent_to</th>\n",
       "      <th>subject</th>\n",
       "      <th>url</th>\n",
       "      <th>version</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_modified</th>\n",
       "      <th>date_processed</th>\n",
       "      <th>text_as_html</th>\n",
       "      <th>emphasized_text_contents</th>\n",
       "      <th>emphasized_text_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97e783aa-0e9e-5880-b675-50653b540ebc</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>Table</td>\n",
       "      <td>d23ad16a-5c65-5bc3-bcd8-534bb13cced1</td>\n",
       "      <td>8c0a032c9cb87b17f493b290f05614b9</td>\n",
       "      <td>message/rfc822</td>\n",
       "      <td>None</td>\n",
       "      <td>Register Now Complimentary Gartner webinars.eml</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"eng\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>[\"QILIANG@CLICKZETTA.COM\"]</td>\n",
       "      <td>Register Now: Complimentary Gartner webinars</td>\n",
       "      <td>s3://unstructured-io/Register Now Complimentar...</td>\n",
       "      <td>284f556327e4a0d3014b8830884a6e60</td>\n",
       "      <td>2025-02-19 18:51:19+08:00</td>\n",
       "      <td>2025-02-19 18:51:19+08:00</td>\n",
       "      <td>2025-02-20 04:12:28.829406+08:00</td>\n",
       "      <td>&lt;table&gt;&lt;tr&gt;&lt;td&gt;Gartner 2025 Leadership Vision ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e243b827-227d-59ea-9022-130b84d085e4</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>CompositeElement</td>\n",
       "      <td>a83718dc-2b6b-554d-861f-16889038e34e</td>\n",
       "      <td>d8cf5ddb47377c8810c275d977500dc0</td>\n",
       "      <td>application/pdf</td>\n",
       "      <td>None</td>\n",
       "      <td>Building an ETL Pipeline using PySpark.ipynb -...</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"eng\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://unstructured-io/Building an ETL Pipeline ...</td>\n",
       "      <td>6d8aa51304c550b26dda27e1137121fc</td>\n",
       "      <td>2025-02-19 04:14:35+08:00</td>\n",
       "      <td>2025-02-19 04:14:35+08:00</td>\n",
       "      <td>2025-02-20 04:12:28.482226+08:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52f1cafa-825f-55db-b567-8f59524c741f</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>CompositeElement</td>\n",
       "      <td>a83718dc-2b6b-554d-861f-16889038e34e</td>\n",
       "      <td>928937e57dfa74001a87cd3b9eb94dc7</td>\n",
       "      <td>application/pdf</td>\n",
       "      <td>None</td>\n",
       "      <td>Building an ETL Pipeline using PySpark.ipynb -...</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"eng\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://unstructured-io/Building an ETL Pipeline ...</td>\n",
       "      <td>6d8aa51304c550b26dda27e1137121fc</td>\n",
       "      <td>2025-02-19 04:14:35+08:00</td>\n",
       "      <td>2025-02-19 04:14:35+08:00</td>\n",
       "      <td>2025-02-20 04:12:28.482226+08:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c0e411e4-fd7c-5c9e-8fe2-12ebf06046c2</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>Table</td>\n",
       "      <td>d23ad16a-5c65-5bc3-bcd8-534bb13cced1</td>\n",
       "      <td>1f6df8c317560b2a22211e5a80a04d78</td>\n",
       "      <td>message/rfc822</td>\n",
       "      <td>None</td>\n",
       "      <td>Register Now Complimentary Gartner webinars.eml</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"eng\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>[\"QILIANG@CLICKZETTA.COM\"]</td>\n",
       "      <td>Register Now: Complimentary Gartner webinars</td>\n",
       "      <td>s3://unstructured-io/Register Now Complimentar...</td>\n",
       "      <td>284f556327e4a0d3014b8830884a6e60</td>\n",
       "      <td>2025-02-19 18:51:19+08:00</td>\n",
       "      <td>2025-02-19 18:51:19+08:00</td>\n",
       "      <td>2025-02-20 04:12:28.829406+08:00</td>\n",
       "      <td>&lt;table&gt;&lt;tr&gt;&lt;td&gt;Trending Now The Art of the 1-P...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ba3b1ee-f29d-54f2-a9bb-036acad78918</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>CompositeElement</td>\n",
       "      <td>a83718dc-2b6b-554d-861f-16889038e34e</td>\n",
       "      <td>dda187b40afb515d4e5e948dcb6c0b68</td>\n",
       "      <td>application/pdf</td>\n",
       "      <td>None</td>\n",
       "      <td>Building an ETL Pipeline using PySpark.ipynb -...</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"eng\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://unstructured-io/Building an ETL Pipeline ...</td>\n",
       "      <td>6d8aa51304c550b26dda27e1137121fc</td>\n",
       "      <td>2025-02-19 04:14:35+08:00</td>\n",
       "      <td>2025-02-19 04:14:35+08:00</td>\n",
       "      <td>2025-02-20 04:12:28.482226+08:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  97e783aa-0e9e-5880-b675-50653b540ebc   \n",
       "1  e243b827-227d-59ea-9022-130b84d085e4   \n",
       "2  52f1cafa-825f-55db-b567-8f59524c741f   \n",
       "3  c0e411e4-fd7c-5c9e-8fe2-12ebf06046c2   \n",
       "4  6ba3b1ee-f29d-54f2-a9bb-036acad78918   \n",
       "\n",
       "                                      record_locator              type  \\\n",
       "0  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...             Table   \n",
       "1  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...  CompositeElement   \n",
       "2  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...  CompositeElement   \n",
       "3  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...             Table   \n",
       "4  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...  CompositeElement   \n",
       "\n",
       "                              record_id                        element_id  \\\n",
       "0  d23ad16a-5c65-5bc3-bcd8-534bb13cced1  8c0a032c9cb87b17f493b290f05614b9   \n",
       "1  a83718dc-2b6b-554d-861f-16889038e34e  d8cf5ddb47377c8810c275d977500dc0   \n",
       "2  a83718dc-2b6b-554d-861f-16889038e34e  928937e57dfa74001a87cd3b9eb94dc7   \n",
       "3  d23ad16a-5c65-5bc3-bcd8-534bb13cced1  1f6df8c317560b2a22211e5a80a04d78   \n",
       "4  a83718dc-2b6b-554d-861f-16889038e34e  dda187b40afb515d4e5e948dcb6c0b68   \n",
       "\n",
       "          filetype file_directory  \\\n",
       "0   message/rfc822           None   \n",
       "1  application/pdf           None   \n",
       "2  application/pdf           None   \n",
       "3   message/rfc822           None   \n",
       "4  application/pdf           None   \n",
       "\n",
       "                                            filename last_modified languages  \\\n",
       "0    Register Now Complimentary Gartner webinars.eml          None   [\"eng\"]   \n",
       "1  Building an ETL Pipeline using PySpark.ipynb -...          None   [\"eng\"]   \n",
       "2  Building an ETL Pipeline using PySpark.ipynb -...          None   [\"eng\"]   \n",
       "3    Register Now Complimentary Gartner webinars.eml          None   [\"eng\"]   \n",
       "4  Building an ETL Pipeline using PySpark.ipynb -...          None   [\"eng\"]   \n",
       "\n",
       "   ...                     sent_to  \\\n",
       "0  ...  [\"QILIANG@CLICKZETTA.COM\"]   \n",
       "1  ...                        None   \n",
       "2  ...                        None   \n",
       "3  ...  [\"QILIANG@CLICKZETTA.COM\"]   \n",
       "4  ...                        None   \n",
       "\n",
       "                                        subject  \\\n",
       "0  Register Now: Complimentary Gartner webinars   \n",
       "1                                          None   \n",
       "2                                          None   \n",
       "3  Register Now: Complimentary Gartner webinars   \n",
       "4                                          None   \n",
       "\n",
       "                                                 url  \\\n",
       "0  s3://unstructured-io/Register Now Complimentar...   \n",
       "1  s3://unstructured-io/Building an ETL Pipeline ...   \n",
       "2  s3://unstructured-io/Building an ETL Pipeline ...   \n",
       "3  s3://unstructured-io/Register Now Complimentar...   \n",
       "4  s3://unstructured-io/Building an ETL Pipeline ...   \n",
       "\n",
       "                            version              date_created  \\\n",
       "0  284f556327e4a0d3014b8830884a6e60 2025-02-19 18:51:19+08:00   \n",
       "1  6d8aa51304c550b26dda27e1137121fc 2025-02-19 04:14:35+08:00   \n",
       "2  6d8aa51304c550b26dda27e1137121fc 2025-02-19 04:14:35+08:00   \n",
       "3  284f556327e4a0d3014b8830884a6e60 2025-02-19 18:51:19+08:00   \n",
       "4  6d8aa51304c550b26dda27e1137121fc 2025-02-19 04:14:35+08:00   \n",
       "\n",
       "              date_modified                   date_processed  \\\n",
       "0 2025-02-19 18:51:19+08:00 2025-02-20 04:12:28.829406+08:00   \n",
       "1 2025-02-19 04:14:35+08:00 2025-02-20 04:12:28.482226+08:00   \n",
       "2 2025-02-19 04:14:35+08:00 2025-02-20 04:12:28.482226+08:00   \n",
       "3 2025-02-19 18:51:19+08:00 2025-02-20 04:12:28.829406+08:00   \n",
       "4 2025-02-19 04:14:35+08:00 2025-02-20 04:12:28.482226+08:00   \n",
       "\n",
       "                                        text_as_html emphasized_text_contents  \\\n",
       "0  <table><tr><td>Gartner 2025 Leadership Vision ...                     None   \n",
       "1                                               None                     None   \n",
       "2                                               None                     None   \n",
       "3  <table><tr><td>Trending Now The Art of the 1-P...                     None   \n",
       "4                                               None                     None   \n",
       "\n",
       "  emphasized_text_tags  \n",
       "0                 None  \n",
       "1                 None  \n",
       "2                 None  \n",
       "3                 None  \n",
       "4                 None  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_ready_data_df = get_rag_ready_data(conn)\n",
    "rag_ready_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d83c30",
   "metadata": {},
   "source": [
    "Or you could check the data Via Singdata Lakehouse Studio.\n",
    "\n",
    "\n",
    "![Image Alt Text](./image/unstructured_table_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fb4febe23f1832",
   "metadata": {
    "id": "b3fb4febe23f1832"
   },
   "source": [
    "### Retrieve relevant documents from Singdata Lakehouse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393cb93e9706feba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T18:15:20.149136Z",
     "start_time": "2024-07-08T18:15:20.143790Z"
    },
    "id": "393cb93e9706feba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liangmo/anaconda3/envs/unstructured/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "def get_embedding(query):\n",
    "    model = SentenceTransformer(\"BAAI/bge-base-en-v1.5\")\n",
    "    return model.encode(query, normalize_embeddings=True)\n",
    "\n",
    "def retrieve_documents(conn, query: str, num_results: int = 5):\n",
    "\n",
    "    embedding = get_embedding(query)\n",
    "    embedding_list = embedding.tolist()\n",
    "    embedding_json = json.dumps(embedding_list)\n",
    "\n",
    "    with conn.cursor() as cur:\n",
    "\n",
    "        stmt = f\"\"\"\n",
    "            WITH \n",
    "            vector_embedding_result AS (\n",
    "            SELECT\n",
    "                \"vector_embedding\" as retrieve_method,\n",
    "                record_locator,\n",
    "                type,\n",
    "                filename,\n",
    "                text,\n",
    "                orig_elements,\n",
    "                cosine_distance(embeddings, cast({embedding_list} as vector({embeddings_dimensions}))) AS score\n",
    "            FROM {silver_table_name}\n",
    "            ORDER BY score ASC\n",
    "            LIMIT {num_results} \n",
    "            )\n",
    "            SELECT    *  FROM      vector_embedding_result\n",
    "           \n",
    "            ORDER by score ASC;\n",
    "        \"\"\"\n",
    "\n",
    "        cur.execute(stmt)\n",
    "\n",
    "        results = cur.fetchall()\n",
    "        columns = [desc[0] for desc in cur.description]  # Get column names from cursor description\n",
    "        df = pd.DataFrame(results, columns=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5999c70db27f0a19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T18:15:21.736297Z",
     "start_time": "2024-07-08T18:15:20.686070Z"
    },
    "id": "5999c70db27f0a19",
    "outputId": "9081a8db-d7c9-45b8-e9f4-41c940c254df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrieve_method</th>\n",
       "      <th>record_locator</th>\n",
       "      <th>type</th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>orig_elements</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vector_embedding</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Register Now Complimentary Gartner webinars.eml</td>\n",
       "      <td>Gartner 2025 Leadership Vision for Digital Tec...</td>\n",
       "      <td>eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...</td>\n",
       "      <td>0.272893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vector_embedding</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Register Now Complimentary Gartner webinars.eml</td>\n",
       "      <td>Harmon, Dave Scott, Bill Schmidt, Chris Teumer...</td>\n",
       "      <td>eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...</td>\n",
       "      <td>0.307342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vector_embedding</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Register Now Complimentary Gartner webinars.eml</td>\n",
       "      <td>a.m. | GMT: 15:00 Presented by: Christie Struc...</td>\n",
       "      <td>eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...</td>\n",
       "      <td>0.318675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vector_embedding</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Register Now Complimentary Gartner webinars.eml</td>\n",
       "      <td>common use cases for GenAI â¢ Learn best practi...</td>\n",
       "      <td>eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...</td>\n",
       "      <td>0.328295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vector_embedding</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Register Now Complimentary Gartner webinars.eml</td>\n",
       "      <td>expectations for your organizationâs GenAI jou...</td>\n",
       "      <td>eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...</td>\n",
       "      <td>0.344925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    retrieve_method                                     record_locator   type  \\\n",
       "0  vector_embedding  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...  Table   \n",
       "1  vector_embedding  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...  Table   \n",
       "2  vector_embedding  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...  Table   \n",
       "3  vector_embedding  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...  Table   \n",
       "4  vector_embedding  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...  Table   \n",
       "\n",
       "                                          filename  \\\n",
       "0  Register Now Complimentary Gartner webinars.eml   \n",
       "1  Register Now Complimentary Gartner webinars.eml   \n",
       "2  Register Now Complimentary Gartner webinars.eml   \n",
       "3  Register Now Complimentary Gartner webinars.eml   \n",
       "4  Register Now Complimentary Gartner webinars.eml   \n",
       "\n",
       "                                                text  \\\n",
       "0  Gartner 2025 Leadership Vision for Digital Tec...   \n",
       "1  Harmon, Dave Scott, Bill Schmidt, Chris Teumer...   \n",
       "2  a.m. | GMT: 15:00 Presented by: Christie Struc...   \n",
       "3  common use cases for GenAI â¢ Learn best practi...   \n",
       "4  expectations for your organizationâs GenAI jou...   \n",
       "\n",
       "                                       orig_elements     score  \n",
       "0  eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...  0.272893  \n",
       "1  eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...  0.307342  \n",
       "2  eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...  0.318675  \n",
       "3  eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...  0.328295  \n",
       "4  eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...  0.344925  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query_text = \"Harmon, Dave Scott, Bill Schmidt, Chris Teumer â¢ Gain an action plan to hiring top IT talent â¢ Understand how to best position yourself in the market to gain top talent â¢ Learn why CIOs need to pay attention to hiring IT talent Register The Gartner 2025 Technology Adoption Roadmap for Infrastructure & Operations (I&O) Wednesday, February 19, 2025 EST: 10:00 a.m. | GMT: 15:00 Presented by: Ajeeta Malhotra and Amol Nadkarni â¢ Discover why 66% of surveyed technologies are\"\n",
    "query_text = \"What is gartner leadership vision for digital tech?\"\n",
    "retrieve_documents_df = retrieve_documents(conn, query_text)\n",
    "retrieve_documents_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc437868b78a41b0",
   "metadata": {
    "id": "bc437868b78a41b0"
   },
   "outputs": [],
   "source": [
    "def match_all_documents(conn, query: str, num_results: int = 1):\n",
    "    with conn.cursor() as cur:\n",
    "\n",
    "        stmt = f\"\"\"\n",
    "            WITH \n",
    "            scalar_match_all_result AS (\n",
    "            SELECT\n",
    "                \"scalar_match_all\" as retrieve_method,\n",
    "                record_locator,\n",
    "                type,\n",
    "                filename,\n",
    "                text,\n",
    "                orig_elements,\n",
    "                -100 AS score\n",
    "            FROM {silver_table_name}\n",
    "            WHERE match_all(\n",
    "                    text,\n",
    "                    \"{query}\",\n",
    "                    map(\"analyzer\", \"unicode\")\n",
    "                    )\n",
    "            ORDER BY score ASC\n",
    "            LIMIT {num_results} \n",
    "            )\n",
    "            SELECT    *  FROM      scalar_match_all_result\n",
    "            ORDER by score ASC;\n",
    "        \"\"\"\n",
    "\n",
    "        cur.execute(stmt)\n",
    "\n",
    "        results = cur.fetchall()\n",
    "        columns = [desc[0] for desc in cur.description]  # Get column names from cursor description\n",
    "        df = pd.DataFrame(results, columns=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d41fa8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrieve_method</th>\n",
       "      <th>record_locator</th>\n",
       "      <th>type</th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>orig_elements</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [retrieve_method, record_locator, type, filename, text, orig_elements, score]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_all_documents_df = match_all_documents(conn,query_text)\n",
    "match_all_documents_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11220e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_any_documents(conn, query: str, num_results: int = 5):\n",
    "    with conn.cursor() as cur:\n",
    "\n",
    "        stmt = f\"\"\"\n",
    "            WITH \n",
    "            scalar_match_any_result AS (\n",
    "            SELECT\n",
    "                \"scalar_match_any\" as retrieve_method,\n",
    "                record_locator,\n",
    "                type,\n",
    "                filename,\n",
    "                text,\n",
    "                orig_elements,\n",
    "                0 AS score\n",
    "            FROM {silver_table_name}\n",
    "            WHERE match_any(\n",
    "                    text,\n",
    "                    \"{query}\",\n",
    "                    map(\"analyzer\", \"unicode\")\n",
    "                    )\n",
    "            ORDER BY score ASC\n",
    "            LIMIT {num_results} \n",
    "            )\n",
    "            SELECT    *  FROM      scalar_match_any_result\n",
    "            ORDER by score ASC;\n",
    "        \"\"\"\n",
    "\n",
    "        cur.execute(stmt)\n",
    "\n",
    "        results = cur.fetchall()\n",
    "        columns = [desc[0] for desc in cur.description]  # Get column names from cursor description\n",
    "        df = pd.DataFrame(results, columns=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354fd3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrieve_method</th>\n",
       "      <th>record_locator</th>\n",
       "      <th>type</th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>orig_elements</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scalar_match_any</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>CompositeElement</td>\n",
       "      <td>Building an ETL Pipeline using PySpark.ipynb -...</td>\n",
       "      <td>Key Steps in the Pipeline:\\n\\n1-Extract:\\n\\nTh...</td>\n",
       "      <td>eJztVNtu1DAQ/RUrTyC1u3GuTh8pRUIgQNoVL1W1msSTXY...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scalar_match_any</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>CompositeElement</td>\n",
       "      <td>Building an ETL Pipeline using PySpark.ipynb -...</td>\n",
       "      <td>from pyspark.sql.functions import expr # resha...</td>\n",
       "      <td>eJztVN9P2zAQ/les8NBWKyXOzxZpL0NMQprEJNgDoqhy7H...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scalar_match_any</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Register Now Complimentary Gartner webinars.eml</td>\n",
       "      <td>within the C-suite Register CIOs, Take a Blend...</td>\n",
       "      <td>eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scalar_match_any</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Register Now Complimentary Gartner webinars.eml</td>\n",
       "      <td>deemed medium or high value â¢ Understand how c...</td>\n",
       "      <td>eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scalar_match_any</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Register Now Complimentary Gartner webinars.eml</td>\n",
       "      <td>common use cases for GenAI â¢ Learn best practi...</td>\n",
       "      <td>eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    retrieve_method                                     record_locator  \\\n",
       "0  scalar_match_any  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...   \n",
       "1  scalar_match_any  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...   \n",
       "2  scalar_match_any  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...   \n",
       "3  scalar_match_any  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...   \n",
       "4  scalar_match_any  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...   \n",
       "\n",
       "               type                                           filename  \\\n",
       "0  CompositeElement  Building an ETL Pipeline using PySpark.ipynb -...   \n",
       "1  CompositeElement  Building an ETL Pipeline using PySpark.ipynb -...   \n",
       "2             Table    Register Now Complimentary Gartner webinars.eml   \n",
       "3             Table    Register Now Complimentary Gartner webinars.eml   \n",
       "4             Table    Register Now Complimentary Gartner webinars.eml   \n",
       "\n",
       "                                                text  \\\n",
       "0  Key Steps in the Pipeline:\\n\\n1-Extract:\\n\\nTh...   \n",
       "1  from pyspark.sql.functions import expr # resha...   \n",
       "2  within the C-suite Register CIOs, Take a Blend...   \n",
       "3  deemed medium or high value â¢ Understand how c...   \n",
       "4  common use cases for GenAI â¢ Learn best practi...   \n",
       "\n",
       "                                       orig_elements  score  \n",
       "0  eJztVNtu1DAQ/RUrTyC1u3GuTh8pRUIgQNoVL1W1msSTXY...      0  \n",
       "1  eJztVN9P2zAQ/les8NBWKyXOzxZpL0NMQprEJNgDoqhy7H...      0  \n",
       "2  eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...      0  \n",
       "3  eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...      0  \n",
       "4  eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...      0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_any_documents_df = match_any_documents(conn,query_text)\n",
    "match_any_documents_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112cf846",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r9/488w9h4n6c746kfyb8ykc0mw0000gp/T/ipykernel_83980/1788529443.py:1: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([retrieve_documents_df, match_all_documents_df, match_any_documents_df], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrieve_method</th>\n",
       "      <th>record_locator</th>\n",
       "      <th>type</th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>orig_elements</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>scalar_match_any</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>CompositeElement</td>\n",
       "      <td>Building an ETL Pipeline using PySpark.ipynb -...</td>\n",
       "      <td>Key Steps in the Pipeline:\\n\\n1-Extract:\\n\\nTh...</td>\n",
       "      <td>eJztVNtu1DAQ/RUrTyC1u3GuTh8pRUIgQNoVL1W1msSTXY...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>scalar_match_any</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>CompositeElement</td>\n",
       "      <td>Building an ETL Pipeline using PySpark.ipynb -...</td>\n",
       "      <td>from pyspark.sql.functions import expr # resha...</td>\n",
       "      <td>eJztVN9P2zAQ/les8NBWKyXOzxZpL0NMQprEJNgDoqhy7H...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>scalar_match_any</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Register Now Complimentary Gartner webinars.eml</td>\n",
       "      <td>within the C-suite Register CIOs, Take a Blend...</td>\n",
       "      <td>eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>scalar_match_any</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Register Now Complimentary Gartner webinars.eml</td>\n",
       "      <td>deemed medium or high value â¢ Understand how c...</td>\n",
       "      <td>eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>scalar_match_any</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Register Now Complimentary Gartner webinars.eml</td>\n",
       "      <td>common use cases for GenAI â¢ Learn best practi...</td>\n",
       "      <td>eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vector_embedding</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Register Now Complimentary Gartner webinars.eml</td>\n",
       "      <td>Gartner 2025 Leadership Vision for Digital Tec...</td>\n",
       "      <td>eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...</td>\n",
       "      <td>0.272893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vector_embedding</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Register Now Complimentary Gartner webinars.eml</td>\n",
       "      <td>Harmon, Dave Scott, Bill Schmidt, Chris Teumer...</td>\n",
       "      <td>eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...</td>\n",
       "      <td>0.307342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vector_embedding</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Register Now Complimentary Gartner webinars.eml</td>\n",
       "      <td>a.m. | GMT: 15:00 Presented by: Christie Struc...</td>\n",
       "      <td>eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...</td>\n",
       "      <td>0.318675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vector_embedding</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Register Now Complimentary Gartner webinars.eml</td>\n",
       "      <td>common use cases for GenAI â¢ Learn best practi...</td>\n",
       "      <td>eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...</td>\n",
       "      <td>0.328295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vector_embedding</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Register Now Complimentary Gartner webinars.eml</td>\n",
       "      <td>expectations for your organizationâs GenAI jou...</td>\n",
       "      <td>eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...</td>\n",
       "      <td>0.344925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    retrieve_method                                     record_locator  \\\n",
       "5  scalar_match_any  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...   \n",
       "6  scalar_match_any  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...   \n",
       "7  scalar_match_any  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...   \n",
       "8  scalar_match_any  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...   \n",
       "9  scalar_match_any  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...   \n",
       "0  vector_embedding  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...   \n",
       "1  vector_embedding  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...   \n",
       "2  vector_embedding  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...   \n",
       "3  vector_embedding  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...   \n",
       "4  vector_embedding  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...   \n",
       "\n",
       "               type                                           filename  \\\n",
       "5  CompositeElement  Building an ETL Pipeline using PySpark.ipynb -...   \n",
       "6  CompositeElement  Building an ETL Pipeline using PySpark.ipynb -...   \n",
       "7             Table    Register Now Complimentary Gartner webinars.eml   \n",
       "8             Table    Register Now Complimentary Gartner webinars.eml   \n",
       "9             Table    Register Now Complimentary Gartner webinars.eml   \n",
       "0             Table    Register Now Complimentary Gartner webinars.eml   \n",
       "1             Table    Register Now Complimentary Gartner webinars.eml   \n",
       "2             Table    Register Now Complimentary Gartner webinars.eml   \n",
       "3             Table    Register Now Complimentary Gartner webinars.eml   \n",
       "4             Table    Register Now Complimentary Gartner webinars.eml   \n",
       "\n",
       "                                                text  \\\n",
       "5  Key Steps in the Pipeline:\\n\\n1-Extract:\\n\\nTh...   \n",
       "6  from pyspark.sql.functions import expr # resha...   \n",
       "7  within the C-suite Register CIOs, Take a Blend...   \n",
       "8  deemed medium or high value â¢ Understand how c...   \n",
       "9  common use cases for GenAI â¢ Learn best practi...   \n",
       "0  Gartner 2025 Leadership Vision for Digital Tec...   \n",
       "1  Harmon, Dave Scott, Bill Schmidt, Chris Teumer...   \n",
       "2  a.m. | GMT: 15:00 Presented by: Christie Struc...   \n",
       "3  common use cases for GenAI â¢ Learn best practi...   \n",
       "4  expectations for your organizationâs GenAI jou...   \n",
       "\n",
       "                                       orig_elements     score  \n",
       "5  eJztVNtu1DAQ/RUrTyC1u3GuTh8pRUIgQNoVL1W1msSTXY...  0.000000  \n",
       "6  eJztVN9P2zAQ/les8NBWKyXOzxZpL0NMQprEJNgDoqhy7H...  0.000000  \n",
       "7  eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...  0.000000  \n",
       "8  eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...  0.000000  \n",
       "9  eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...  0.000000  \n",
       "0  eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...  0.272893  \n",
       "1  eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...  0.307342  \n",
       "2  eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...  0.318675  \n",
       "3  eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...  0.328295  \n",
       "4  eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...  0.344925  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.concat([retrieve_documents_df, match_all_documents_df, match_any_documents_df], ignore_index=True)\n",
    "merged_df = merged_df.sort_values(by='score', ascending=True)\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d90305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "\n",
    "# Define the rerank function\n",
    "def rerank_texts(query, texts, model_name=\"BAAI/bge-reranker-v2-m3\", normalize=True):\n",
    "    \"\"\"\n",
    "    Rerank a list of texts based on their relevance to a given query using the specified reranker model.\n",
    "\n",
    "    Parameters:\n",
    "    - query: The query string.\n",
    "    - texts: List of texts to be reranked.\n",
    "    - model_name: The name of the reranker model to use.\n",
    "    - normalize: Whether to normalize the scores to the [0, 1] range using the sigmoid function.\n",
    "\n",
    "    Returns:\n",
    "    - A list of reranked texts.\n",
    "    - A list of corresponding scores.\n",
    "    \"\"\"\n",
    "    # Load the model and tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare input pairs [query, text]\n",
    "    pairs = [[query, text] for text in texts]\n",
    "    inputs = tokenizer(pairs, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "    # Get relevance scores\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        scores = outputs.logits.view(-1).cpu().numpy()\n",
    "\n",
    "    # Normalize scores to [0, 1] if required\n",
    "    if normalize:\n",
    "        scores = 1 / (1 + np.exp(-scores))\n",
    "\n",
    "    # Combine texts with scores and sort by score in descending order\n",
    "    scored_texts = list(zip(texts, scores))\n",
    "    scored_texts.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Separate the sorted texts and scores\n",
    "    sorted_texts, sorted_scores = zip(*scored_texts)\n",
    "\n",
    "    return list(sorted_texts), list(sorted_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0061aefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# query = \"Which session is presented by Ajeeta Malhotra and Amol Nadkarni?\"\n",
    "query = \"What is gartner leadership vision for digital tech?\"\n",
    "sorted_texts, sorted_scores = rerank_texts(query, merged_df[\"text\"].tolist())\n",
    "\n",
    "# Update DataFrame with reranked texts and scores\n",
    "merged_df[\"reranked_text\"] = sorted_texts\n",
    "merged_df[\"rerank_score\"] = sorted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ef1a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrieve_method</th>\n",
       "      <th>record_locator</th>\n",
       "      <th>type</th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>orig_elements</th>\n",
       "      <th>score</th>\n",
       "      <th>reranked_text</th>\n",
       "      <th>rerank_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>scalar_match_any</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>CompositeElement</td>\n",
       "      <td>Building an ETL Pipeline using PySpark.ipynb -...</td>\n",
       "      <td>Key Steps in the Pipeline:\\n\\n1-Extract:\\n\\nTh...</td>\n",
       "      <td>eJztVNtu1DAQ/RUrTyC1u3GuTh8pRUIgQNoVL1W1msSTXY...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Gartner 2025 Leadership Vision for Digital Tec...</td>\n",
       "      <td>0.725993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>scalar_match_any</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>CompositeElement</td>\n",
       "      <td>Building an ETL Pipeline using PySpark.ipynb -...</td>\n",
       "      <td>from pyspark.sql.functions import expr # resha...</td>\n",
       "      <td>eJztVN9P2zAQ/les8NBWKyXOzxZpL0NMQprEJNgDoqhy7H...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>common use cases for GenAI â¢ Learn best practi...</td>\n",
       "      <td>0.603706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>scalar_match_any</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Register Now Complimentary Gartner webinars.eml</td>\n",
       "      <td>within the C-suite Register CIOs, Take a Blend...</td>\n",
       "      <td>eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>common use cases for GenAI â¢ Learn best practi...</td>\n",
       "      <td>0.603706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>scalar_match_any</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Register Now Complimentary Gartner webinars.eml</td>\n",
       "      <td>deemed medium or high value â¢ Understand how c...</td>\n",
       "      <td>eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>a.m. | GMT: 15:00 Presented by: Christie Struc...</td>\n",
       "      <td>0.561251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>scalar_match_any</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Register Now Complimentary Gartner webinars.eml</td>\n",
       "      <td>common use cases for GenAI â¢ Learn best practi...</td>\n",
       "      <td>eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>expectations for your organizationâs GenAI jou...</td>\n",
       "      <td>0.018261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vector_embedding</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Register Now Complimentary Gartner webinars.eml</td>\n",
       "      <td>Gartner 2025 Leadership Vision for Digital Tec...</td>\n",
       "      <td>eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...</td>\n",
       "      <td>0.272893</td>\n",
       "      <td>Harmon, Dave Scott, Bill Schmidt, Chris Teumer...</td>\n",
       "      <td>0.004540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vector_embedding</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Register Now Complimentary Gartner webinars.eml</td>\n",
       "      <td>Harmon, Dave Scott, Bill Schmidt, Chris Teumer...</td>\n",
       "      <td>eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...</td>\n",
       "      <td>0.307342</td>\n",
       "      <td>deemed medium or high value â¢ Understand how c...</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vector_embedding</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Register Now Complimentary Gartner webinars.eml</td>\n",
       "      <td>a.m. | GMT: 15:00 Presented by: Christie Struc...</td>\n",
       "      <td>eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...</td>\n",
       "      <td>0.318675</td>\n",
       "      <td>within the C-suite Register CIOs, Take a Blend...</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vector_embedding</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Register Now Complimentary Gartner webinars.eml</td>\n",
       "      <td>common use cases for GenAI â¢ Learn best practi...</td>\n",
       "      <td>eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...</td>\n",
       "      <td>0.328295</td>\n",
       "      <td>from pyspark.sql.functions import expr # resha...</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vector_embedding</td>\n",
       "      <td>{\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Register Now Complimentary Gartner webinars.eml</td>\n",
       "      <td>expectations for your organizationâs GenAI jou...</td>\n",
       "      <td>eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...</td>\n",
       "      <td>0.344925</td>\n",
       "      <td>Key Steps in the Pipeline:\\n\\n1-Extract:\\n\\nTh...</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    retrieve_method                                     record_locator  \\\n",
       "5  scalar_match_any  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...   \n",
       "6  scalar_match_any  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...   \n",
       "7  scalar_match_any  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...   \n",
       "8  scalar_match_any  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...   \n",
       "9  scalar_match_any  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...   \n",
       "0  vector_embedding  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...   \n",
       "1  vector_embedding  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...   \n",
       "2  vector_embedding  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...   \n",
       "3  vector_embedding  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...   \n",
       "4  vector_embedding  {\"protocol\": \"s3\", \"remote_file_path\": \"s3://u...   \n",
       "\n",
       "               type                                           filename  \\\n",
       "5  CompositeElement  Building an ETL Pipeline using PySpark.ipynb -...   \n",
       "6  CompositeElement  Building an ETL Pipeline using PySpark.ipynb -...   \n",
       "7             Table    Register Now Complimentary Gartner webinars.eml   \n",
       "8             Table    Register Now Complimentary Gartner webinars.eml   \n",
       "9             Table    Register Now Complimentary Gartner webinars.eml   \n",
       "0             Table    Register Now Complimentary Gartner webinars.eml   \n",
       "1             Table    Register Now Complimentary Gartner webinars.eml   \n",
       "2             Table    Register Now Complimentary Gartner webinars.eml   \n",
       "3             Table    Register Now Complimentary Gartner webinars.eml   \n",
       "4             Table    Register Now Complimentary Gartner webinars.eml   \n",
       "\n",
       "                                                text  \\\n",
       "5  Key Steps in the Pipeline:\\n\\n1-Extract:\\n\\nTh...   \n",
       "6  from pyspark.sql.functions import expr # resha...   \n",
       "7  within the C-suite Register CIOs, Take a Blend...   \n",
       "8  deemed medium or high value â¢ Understand how c...   \n",
       "9  common use cases for GenAI â¢ Learn best practi...   \n",
       "0  Gartner 2025 Leadership Vision for Digital Tec...   \n",
       "1  Harmon, Dave Scott, Bill Schmidt, Chris Teumer...   \n",
       "2  a.m. | GMT: 15:00 Presented by: Christie Struc...   \n",
       "3  common use cases for GenAI â¢ Learn best practi...   \n",
       "4  expectations for your organizationâs GenAI jou...   \n",
       "\n",
       "                                       orig_elements     score  \\\n",
       "5  eJztVNtu1DAQ/RUrTyC1u3GuTh8pRUIgQNoVL1W1msSTXY...  0.000000   \n",
       "6  eJztVN9P2zAQ/les8NBWKyXOzxZpL0NMQprEJNgDoqhy7H...  0.000000   \n",
       "7  eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...  0.000000   \n",
       "8  eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...  0.000000   \n",
       "9  eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...  0.000000   \n",
       "0  eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...  0.272893   \n",
       "1  eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...  0.307342   \n",
       "2  eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...  0.318675   \n",
       "3  eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...  0.328295   \n",
       "4  eJztXA1zI7eR/SsopZJLqiQtKVFfG5fLWkora3e10kl0tn...  0.344925   \n",
       "\n",
       "                                       reranked_text  rerank_score  \n",
       "5  Gartner 2025 Leadership Vision for Digital Tec...      0.725993  \n",
       "6  common use cases for GenAI â¢ Learn best practi...      0.603706  \n",
       "7  common use cases for GenAI â¢ Learn best practi...      0.603706  \n",
       "8  a.m. | GMT: 15:00 Presented by: Christie Struc...      0.561251  \n",
       "9  expectations for your organizationâs GenAI jou...      0.018261  \n",
       "0  Harmon, Dave Scott, Bill Schmidt, Chris Teumer...      0.004540  \n",
       "1  deemed medium or high value â¢ Understand how c...      0.000239  \n",
       "2  within the C-suite Register CIOs, Take a Blend...      0.000079  \n",
       "3  from pyspark.sql.functions import expr # resha...      0.000017  \n",
       "4  Key Steps in the Pipeline:\\n\\n1-Extract:\\n\\nTh...      0.000016  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65f6c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gartner 2025 Leadership Vision for Digital Technology and Business Services Wednesday, February 19, 2025 EST: 11:00 a.m. | GMT: 16:00 Presented by: Chrissy Healey, Scott Frederick and Jennifer Barry â¢ Revert back to growth by defining and delivering transformative impact â¢ Resolve the asset and AI-first dilemma in delivery â¢ Decode demand in your top accounts Register How U.S. Government Executives Can Navigate Upcoming Workforce Changes Friday, February 21, 2025 EDT: 10:00\n"
     ]
    }
   ],
   "source": [
    "# Get the first row of the DataFrame, which get the highest rerank_score\n",
    "first_row_reranked_text = merged_df.iloc[0]['reranked_text']\n",
    "print(first_row_reranked_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34eaa67",
   "metadata": {},
   "source": [
    "### Summary Benefits for RAG Application Development\n",
    "\n",
    "![Image Alt Text](./image/UnstructuredDataPipelineBenifits.png)\n",
    "\n",
    "\n",
    "**Enhanced Search Efficiency:** \n",
    "- By supporting both inverted and vector searches, this table allows RAG applications to efficiently retrieve relevant information based on both text content and semantic similarity. This enhances the model's ability to find and generate contextually relevant responses.\n",
    "\n",
    "**Improved Accuracy:** \n",
    "- The combination of full-text and similarity searches ensures that RAG applications can access a broader range of relevant data, improving the accuracy and relevance of generated content.\n",
    "\n",
    "**Scalability:** \n",
    "- With optimized indexes, the table can handle large volumes of data and perform searches quickly, supporting the scalability needs of RAG applications.\n",
    "\n",
    "**Simplified Architecture:** \n",
    "- Combining inverted text and vector search capabilities in a single table eliminates the need for separate text and vector search databases. This simplifies maintenance, reduces operational overhead, and improves development efficiency.\n",
    "\n",
    "**Data Consistency:** \n",
    "- Reducing the number of data replicas from three to one enhances data consistency, minimizes data duplication, and reduces the need for data synchronization and movement.\n",
    "\n",
    "Overall, this Singdata Lakehouse architecture reduces operational complexity, enhances data consistency, and improves development efficiency, making it ideal for effective RAG application development."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
